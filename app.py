import streamlit as st
import re
import io
import os
from PIL import Image
import pytesseract
import pandas as pd
import cv2
import numpy as np
from pdf2image import convert_from_bytes
import pdfplumber

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="AI Medical Analyzer Pro", page_icon="ğŸ©º", layout="wide")

# --- ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† CSV (Ù…Ø¹ ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡) ---
@st.cache_data
def load_tests_database(path="tests_database.csv"):
    try:
        df = pd.read_csv(path, dtype=str).fillna('')
    except FileNotFoundError:
        st.error(f"Ø®Ø·Ø£ ÙØ§Ø¯Ø­: Ù…Ù„Ù Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª '{path}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚.")
        return None, None, None

    tests = {}
    aliases = {}
    recommendations = {}
    for _, row in df.iterrows():
        key = row['code'].strip().lower()
        if not key: continue

        # Ø¥ØµÙ„Ø§Ø­ Ø­Ø§Ø³Ù…: Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ© Ù‚Ø¨Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„
        try:
            low = float(row['low']) if row['low'] else None
            high = float(row['high']) if row['high'] else None
        except (ValueError, TypeError):
            low, high = None, None

        tests[key] = {
            'range': (low, high) if low is not None and high is not None else None,
            'unit': row.get('unit', ''),
            'name_ar': row.get('name_ar', key),
            'name_en': row.get('name_en', key),
        }
        
        for alias_col in ['aliases', 'name_en', 'name_ar']:
            if row.get(alias_col):
                for a in row[alias_col].split(';'):
                    cleaned_alias = a.strip().lower()
                    if cleaned_alias:
                        aliases[cleaned_alias] = key
        
        rec = {}
        if row.get('recommendation_low'): rec['Ù…Ù†Ø®ÙØ¶'] = row['recommendation_low']
        if row.get('recommendation_high'): rec['Ù…Ø±ØªÙØ¹'] = row['recommendation_high']
        if rec: recommendations[key] = rec
        
    return tests, aliases, recommendations

TESTS_DB, ALIASES, RECOMMENDATIONS = load_tests_database()

# --- Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ù†Øµ (Ù…Ø­Ø³Ù†Ø©) ---
def preprocess_image_bytes(file_bytes):
    img_arr = np.frombuffer(file_bytes, np.uint8)
    img = cv2.imdecode(img_arr, cv2.IMREAD_COLOR)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
    return Image.fromarray(thresh)

def ocr_image(img_pil):
    config = r'--oem 3 --psm 6'
    return pytesseract.image_to_string(img_pil, lang='eng+ara', config=config)

def extract_text_from_file(file_bytes, file_type):
    if file_type == "application/pdf":
        text = ""
        try:
            with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
                for page in pdf.pages:
                    text += page.extract_text() + "\n"
        except Exception:
            pass
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ù„Ù PDF Ù…Ù…Ø³ÙˆØ­Ø§Ù‹ Ø¶ÙˆØ¦ÙŠØ§Ù‹ (Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†Øµ)
        if not text.strip():
            images = convert_from_bytes(file_bytes)
            for img in images:
                text += ocr_image(img) + "\n"
        return text
    else: # Ù„Ù„ØµÙˆØ±
        processed_img = preprocess_image_bytes(file_bytes)
        return ocr_image(processed_img)

# --- Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ (Ù…Ø¨Ø³Ø·Ø© ÙˆØ£ÙƒØ«Ø± Ù‚ÙˆØ©) ---
def analyze_text_robust(text, tests_db, aliases_db):
    text_lower = text.lower()
    
    found_tests = []
    for alias, key in aliases_db.items():
        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… `\b` Ù„Ø¶Ù…Ø§Ù† Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ÙƒÙ„Ù…Ø© ÙƒØ§Ù…Ù„Ø©
            for match in re.finditer(r'\b' + re.escape(alias) + r'\b', text_lower):
                found_tests.append({'key': key, 'pos': match.start(), 'end': match.end()})
        except re.error:
            continue # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· ØºÙŠØ± Ø§Ù„ØµØ§Ù„Ø­Ø©

    numbers = [(m.group(1), m.start()) for m in re.finditer(r'(\d+\.?\d*)', text_lower)]
    
    results = []
    used_keys = set()
    found_tests.sort(key=lambda x: x['pos'])

    for test in found_tests:
        key = test['key']
        if key in used_keys: continue

        best_candidate_num = None
        min_distance = float('inf')

        for num_val, num_pos in numbers:
            distance = num_pos - test['end']
            if 0 <= distance < min_distance:
                is_interrupted = any(other['pos'] > test['pos'] and other['pos'] < num_pos for other in found_tests)
                if not is_interrupted:
                    min_distance = distance
                    best_candidate_num = num_val
        
        if best_candidate_num:
            try:
                value = float(best_candidate_num)
                meta = tests_db[key]
                rng = meta.get('range')
                status = "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
                
                if rng:
                    low, high = rng
                    if value < low: status = "Ù…Ù†Ø®ÙØ¶"
                    elif value > high: status = "Ù…Ø±ØªÙØ¹"
                    else: status = "Ø·Ø¨ÙŠØ¹ÙŠ"
                
                rec = RECOMMENDATIONS.get(key, {})
                recommendation = rec.get(status, '')

                results.append({
                    'name': f"ğŸ”¬ {meta.get('name_ar', key)}",
                    'value_str': best_candidate_num,
                    'status': status,
                    'range_str': f"{rng[0]} - {rng[1]} {meta.get('unit', '')}" if rng else 'N/A',
                    'recommendation': recommendation
                })
                used_keys.add(key)
            except (ValueError, KeyError):
                continue
    return results

# --- Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨Ø·Ø§Ù‚Ø§Øª Ø§Ù„Ù…Ù„ÙˆÙ†Ø©) ---
def display_results_as_cards(results):
    st.subheader("ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„")
    colors = {"Ø·Ø¨ÙŠØ¹ÙŠ": "#2E8B57", "Ù…Ù†Ø®ÙØ¶": "#DAA520", "Ù…Ø±ØªÙØ¹": "#DC143C", "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ": "#808080"}
    
    for res in results:
        color = colors.get(res['status'], "#808080")
        st.markdown(f"""
        <div style="background-color: #f0f2f6; border-radius: 10px; padding: 15px; margin-bottom: 10px; border-left: 5px solid {color};">
            <h4 style="margin-top: 0; margin-bottom: 10px; color: #003366;">{res['name']}</h4>
            <div style="display: flex; justify-content: space-between;">
                <div>
                    <p style="margin: 0;"><strong>Ø§Ù„Ù†ØªÙŠØ¬Ø©:</strong> {res['value_str']}</p>
                    <p style="margin: 0;"><strong>Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ:</strong> {res['range_str']}</p>
                </div>
                <div style="color: {color}; font-weight: bold; font-size: 1.2em;">{res["status"]}</div>
            </div>
            {f"<div style='background-color: #e1ecf4; border-radius: 5px; padding: 10px; margin-top: 10px; font-size: 0.9em; color: #333;'>ğŸ’¡ <strong>Ù…Ù„Ø§Ø­Ø¸Ø©:</strong> {res['recommendation']}</div>" if res["recommendation"] else ""}
        </div>
        """, unsafe_allow_html=True)

# --- Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---
st.title("ğŸ©º Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø·Ø¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ Pro")
st.sidebar.header("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
st.sidebar.info("Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù‡Ùˆ Ø£Ø¯Ø§Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© ÙˆÙ„Ø§ ÙŠØºÙ†ÙŠ Ø¹Ù† Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ø·Ø¨ÙŠØ¨ Ø§Ù„Ù…Ø®ØªØµ.")
st.sidebar.markdown("---")

if TESTS_DB: # Ù„Ø§ ØªÙ‚Ù… Ø¨ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¥Ø°Ø§ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    mode = st.sidebar.radio("Ø§Ø®ØªØ± Ø§Ù„Ø®Ø¯Ù…Ø©:", ["ğŸ”¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ©", "ğŸ’¬ Ø§Ø³ØªØ´Ø§Ø±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶"])
    
    if mode == "ğŸ”¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ©":
        st.header("ğŸ”¬ ØªØ­Ù„ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ø·Ø¨ÙŠ")
        uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØ±Ø© Ø£Ùˆ PDF", type=['png','jpg','jpeg','pdf'])

        if uploaded_file:
            file_bytes = uploaded_file.getvalue()
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ù…Ù„Ù..."):
                text = extract_text_from_file(file_bytes, uploaded_file.type)

            if not text or not text.strip():
                st.error("Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ù† Ø§Ø³ØªØ®Ù„Ø§Øµ Ø£ÙŠ Ù†Øµ. Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ù„Ù Ø£ÙˆØ¶Ø­.")
            else:
                results = analyze_text_robust(text, TESTS_DB, ALIASES)
                
                if results:
                    display_results_as_cards(results)
                else:
                    st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ ÙØ­ÙˆØµØ§Øª Ù…Ø¯Ø¹ÙˆÙ…Ø© ÙÙŠ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬.")

                with st.expander("ğŸ“„ Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ (Ù„Ù„ØªØ¯Ù‚ÙŠÙ‚)"):
                    st.text_area("", text, height=300)

    elif mode == "ğŸ’¬ Ø§Ø³ØªØ´Ø§Ø±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶":
        st.header("ğŸ’¬ Ø§Ø³ØªØ´Ø§Ø±Ø© Ø£ÙˆÙ„ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶")
        # (ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© ÙƒÙˆØ¯ Ø§Ù„Ø§Ø³ØªØ´Ø§Ø±Ø© Ù‡Ù†Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹)
        st.info("Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙŠØ²Ø© Ù‚ÙŠØ¯ Ø§Ù„ØªØ·ÙˆÙŠØ±.")
