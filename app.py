import streamlit as st
import re
import io
from PIL import Image
import pytesseract
import pdfplumber
import pandas as pd
import cv2
import numpy as np
from pdf2image import convert_from_bytes
import joblib
import os
import urllib.request
from pathlib import Path

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="AI Medical Analyzer", page_icon="ğŸ©º", layout="wide")

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¬Ø¯ÙŠØ¯ (TFLite) ---
MODEL_URL = "https://github.com/tulasiram58827/ocr_tflite/raw/main/models/keras_ocr_float16.tflite"
MODEL_LOCAL_PATH = Path("models/keras_ocr_float16.tflite")

# --- Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ù„Ø¨ÙŠØ¦Ø© Streamlit Cloud ---
pytesseract.pytesseract.tesseract_cmd = 'tesseract'
POPPLER_PATH = '/usr/bin'

# --- Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ­ÙˆØµØ§Øª ---
# (Ù†ÙØ³ Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„ÙƒØ¨ÙŠØ± Ø§Ù„Ø°ÙŠ Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§Ù‡ ÙÙŠ Ø§Ù„Ù…Ø±Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©)
NORMAL_RANGES = {
    "wbc": {"range": (4.0, 11.0), "unit": "x10^9/L", "name_ar": "ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡"},
    "rbc": {"range": (4.1, 5.7), "unit": "x10^12/L", "name_ar": "ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø­Ù…Ø±Ø§Ø¡"},
    "hemoglobin": {"range": (13.0, 18.0), "unit": "g/dL", "name_ar": "Ø§Ù„Ù‡ÙŠÙ…ÙˆØºÙ„ÙˆØ¨ÙŠÙ†"},
    "hematocrit": {"range": (40, 54), "unit": "%", "name_ar": "Ø§Ù„Ù‡ÙŠÙ…Ø§ØªÙˆÙƒØ±ÙŠØª"},
    "platelets": {"range": (150, 450), "unit": "x10^9/L", "name_ar": "Ø§Ù„ØµÙØ§Ø¦Ø­ Ø§Ù„Ø¯Ù…ÙˆÙŠØ©"},
    "neutrophils": {"range": (40, 70), "unit": "%", "name_ar": "Ø§Ù„Ø¹Ø¯Ù„Ø§Øª"},
    "lymphocytes": {"range": (20, 45), "unit": "%", "name_ar": "Ø§Ù„Ù„Ù…ÙØ§ÙˆÙŠØ§Øª"},
    "glucose": {"range": (70, 140), "unit": "mg/dL", "name_ar": "Ø§Ù„Ø¬Ù„ÙˆÙƒÙˆØ² (Ø§Ù„Ø³ÙƒØ±)"},
}
ALIASES = {
    "hb": "hemoglobin", "hgb": "hemoglobin", "pcv": "hematocrit", "hct": "hematocrit",
    "t.wbc": "wbc", "w.b.c": "wbc", "wbc count": "wbc", "t.w.b.c": "wbc",
    "lymphocyte": "lymphocytes", "blood sugar": "glucose", "sugar": "glucose",
}

# --- Ø¯ÙˆØ§Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¬Ø¯ÙŠØ¯ (TFLite OCR) ---
@st.cache_resource
def download_model(url=MODEL_URL, local_path=MODEL_LOCAL_PATH):
    """ØªÙ†Ø²ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§."""
    if local_path.exists():
        return True
    local_path.parent.mkdir(parents=True, exist_ok=True)
    try:
        with st.spinner(f"Downloading TFLite OCR model (~23MB)..."):
            urllib.request.urlretrieve(url, str(local_path))
        return True
    except Exception as e:
        st.error(f"Failed to download TFLite model: {e}")
        return False

@st.cache_resource
def init_keras_ocr():
    """Ø¥Ø¹Ø¯Ø§Ø¯ Ø£Ø¯ÙˆØ§Øª Keras-OCR."""
    import keras_ocr
    pipeline = keras_ocr.pipeline.Pipeline()
    return pipeline

def run_keras_ocr(image, pipeline):
    """ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ."""
    if isinstance(image, np.ndarray):
        images = [image]
    else: # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª PIL Image
        images = [np.array(image)]
    
    prediction_groups = pipeline.recognize(images)
    
    # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
    text = ""
    for predictions in prediction_groups[0]:
        text += predictions[0] + " "
    return text

# --- Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ (Ù…Ø¹Ø¯Ù„Ø©) ---
def extract_text_from_image(file_bytes, engine='pytesseract'):
    try:
        img = Image.open(io.BytesIO(file_bytes))
        if engine == 'tflite':
            if download_model():
                pipeline = init_keras_ocr()
                text = run_keras_ocr(img, pipeline)
                return text, None
            else:
                return None, "Could not use TFLite model."
        else: # Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù‡Ùˆ pytesseract
            text = pytesseract.image_to_string(img, lang="eng+ara")
            return text, None
    except Exception as e:
        return None, f"OCR Error: {e}"

def analyze_text(text):
    # (Ù†ÙØ³ Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚ÙˆÙŠØ© Ø§Ù„ØªÙŠ Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§Ù‡Ø§ ÙÙŠ Ø§Ù„Ù…Ø±Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©)
    results = []
    if not text: return results
    text_lower = text.lower()
    processed_tests = set()
    for key, details in NORMAL_RANGES.items():
        if key in processed_tests: continue
        aliases = [k for k, v in ALIASES.items() if v == key]
        search_keys = [key] + aliases
        pattern_keys = '|'.join([re.escape(k).replace(r"\_", "_").replace(".", r"\.?") for k in search_keys])
        pattern = re.compile(rf"\b({pattern_keys})\b\s*[:\-=]*\s*([0-9]+(?:\.[0-9]+)?)", re.IGNORECASE)
        matches = pattern.finditer(text_lower)
        for m in matches:
            try:
                value = float(m.group(2))
                if key in processed_tests: continue
                low, high = details["range"]
                status = "Normal"
                if value < low: status = "Low"
                elif value > high: status = "High"
                results.append({
                    "Ø§Ù„ÙØ­Øµ": details["name_ar"], "Ø§Ù„Ù‚ÙŠÙ…Ø©": value, "Ø§Ù„ÙˆØ­Ø¯Ø©": details["unit"],
                    "Ø§Ù„Ø­Ø§Ù„Ø©": status, "Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ": f"{low}-{high}"
                })
                processed_tests.add(key)
                break 
            except: continue
    return results

# --- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ---
st.title("ğŸ©º Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø·Ø¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ (Ù…Ø¹ Ù…Ø­Ø±Ùƒ TFLite)")

st.sidebar.header("ğŸ“Œ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©")
ocr_engine = st.sidebar.selectbox("Ø§Ø®ØªØ± Ù…Ø­Ø±Ùƒ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†ØµÙˆØµ (OCR):", ["pytesseract (Ø³Ø±ÙŠØ¹)", "TFLite (Ø£ÙƒØ«Ø± Ø¯Ù‚Ø©)"])

uploaded_file = st.sidebar.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØ±Ø©", type=["png","jpg","jpeg"])

if uploaded_file:
    with st.spinner(f"Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… {ocr_engine}..."):
        file_bytes = uploaded_file.getvalue()
        text, err = extract_text_from_image(file_bytes, engine=ocr_engine)
        
        if err:
            st.error(err)
        elif text:
            st.subheader("ğŸ“„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬:")
            st.text_area("Extracted Text", text, height=200)
            results = analyze_text(text)
            if results:
                df = pd.DataFrame(results)
                st.subheader("ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„:")
                st.dataframe(df, use_container_width=True)
            else:
                st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø£ÙŠ ÙØ­ÙˆØµØ§Øª.")
        else:
            st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙŠ Ù†Øµ.")
