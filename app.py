import streamlit as st
import re
import io
import numpy as np
import pandas as pd
from openai import OpenAI
import cv2
import easyocr
import pytesseract # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯Ù‡ Ù„Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ù‡Ø¬ÙŠÙ†
import joblib
from PIL import Image
import os
from tensorflow.keras.models import load_model
import altair as alt

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(
    page_title="AI Medical Suite",
    page_icon="âš•ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ (Ù…Ø¹ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª) ---
@st.cache_resource
def load_ocr_models():
    """ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø±Ø¦ EasyOCR (Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø«Ù‚ÙŠÙ„)."""
    return easyocr.Reader(['en', 'ar'])

@st.cache_data
def load_symptom_checker():
    """ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¯Ù‚Ù‚ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶."""
    try:
        s_model = joblib.load('symptom_checker_model.joblib')
        s_data = pd.read_csv('Training.csv')
        s_list = s_data.columns[:-1].tolist()
        return s_model, s_list
    except FileNotFoundError:
        return None, None

@st.cache_resource
def load_ecg_analyzer():
    """ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ù„Ù„ ECG."""
    try:
        ecg_model = load_model("ecg_classifier_model.h5")
        ecg_signals = np.load("sample_ecg_signals.npy", allow_pickle=True).item()
        return ecg_model, ecg_signals
    except FileNotFoundError:
        return None, None

# --- Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„Ø© ---
KNOWLEDGE_BASE = {
    "wbc": {"name_ar": "ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡", "range": (4.0, 11.0), "unit": "x10^9/L", "category": "Ø§Ù„Ø§Ù„ØªÙ‡Ø§Ø¨Ø§Øª ÙˆØ§Ù„Ù…Ù†Ø§Ø¹Ø©", "recommendation_high": "Ø§Ø±ØªÙØ§Ø¹ Ù‚Ø¯ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø¹Ø¯ÙˆÙ‰ Ø¨ÙƒØªÙŠØ±ÙŠØ©.", "recommendation_low": "Ø§Ù†Ø®ÙØ§Ø¶ Ù‚Ø¯ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø¶Ø¹Ù Ù…Ù†Ø§Ø¹ÙŠ."},
    "rbc": {"name_ar": "ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø­Ù…Ø±Ø§Ø¡", "range": (4.1, 5.9), "unit": "x10^12/L", "category": "ÙØ­ÙˆØµØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø¹Ø§Ù…Ø©", "recommendation_high": "Ø§Ø±ØªÙØ§Ø¹ Ù‚Ø¯ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ø¬ÙØ§Ù.", "recommendation_low": "Ø§Ù†Ø®ÙØ§Ø¶ Ù‚Ø¯ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ ÙÙ‚Ø± Ø¯Ù…."},
    "hemoglobin": {"name_ar": "Ø§Ù„Ù‡ÙŠÙ…ÙˆØºÙ„ÙˆØ¨ÙŠÙ†", "range": (13.0, 18.0), "unit": "g/dL", "category": "ÙØ­ÙˆØµØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø¹Ø§Ù…Ø©", "recommendation_high": "Ø§Ø±ØªÙØ§Ø¹ Ù‚Ø¯ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ø¬ÙØ§Ù.", "recommendation_low": "Ø§Ù†Ø®ÙØ§Ø¶ Ù‡Ùˆ Ù…Ø¤Ø´Ø± Ø£Ø³Ø§Ø³ÙŠ Ø¹Ù„Ù‰ ÙÙ‚Ø± Ø§Ù„Ø¯Ù…."},
    "glucose": {"name_ar": "Ø³ÙƒØ± Ø§Ù„Ø¯Ù…", "range": (70, 100), "unit": "mg/dL", "category": "Ø³ÙƒØ± Ø§Ù„Ø¯Ù…", "recommendation_high": "Ù‚Ø¯ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø³ÙƒØ±ÙŠ Ø£Ùˆ Ù…Ù‚Ø§ÙˆÙ…Ø© Ù„Ù„Ø£Ù†Ø³ÙˆÙ„ÙŠÙ†.", "recommendation_low": "Ù‚Ø¯ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ù‡Ø¨ÙˆØ· Ø³ÙƒØ±."},
    "creatinine": {"name_ar": "Ø§Ù„ÙƒØ±ÙŠØ§ØªÙŠÙ†ÙŠÙ†", "range": (0.6, 1.3), "unit": "mg/dL", "category": "ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ÙƒÙ„Ù‰", "recommendation_high": "Ø§Ø±ØªÙØ§Ø¹ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø¶Ø¹Ù Ù…Ø­ØªÙ…Ù„ ÙÙŠ ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ÙƒÙ„Ù‰.", "recommendation_low": "Ø¹Ø§Ø¯Ø© Ù„Ø§ ÙŠØ«ÙŠØ± Ø§Ù„Ù‚Ù„Ù‚."},
    "alt": {"name_ar": "Ø¥Ù†Ø²ÙŠÙ… ALT", "range": (7, 56), "unit": "U/L", "category": "ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ÙƒØ¨Ø¯", "recommendation_high": "Ø§Ø±ØªÙØ§Ø¹ Ù‚Ø¯ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ‡Ø§Ø¨ Ø£Ùˆ ØªÙ„Ù ÙÙŠ Ø§Ù„ÙƒØ¨Ø¯.", "recommendation_low": ""},
    "ast": {"name_ar": "Ø¥Ù†Ø²ÙŠÙ… AST", "range": (10, 40), "unit": "U/L", "category": "ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ÙƒØ¨Ø¯", "recommendation_high": "Ø§Ø±ØªÙØ§Ø¹ Ù‚Ø¯ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ ØªÙ„Ù ÙÙŠ Ø§Ù„ÙƒØ¨Ø¯ Ø£Ùˆ Ø§Ù„Ø¹Ø¶Ù„Ø§Øª.", "recommendation_low": ""},
    # ... ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¶Ø§ÙØ© Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙØ­ÙˆØµØ§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ Ù‡Ù†Ø§ Ø¨Ù†ÙØ³ Ø§Ù„Ù‡ÙŠÙƒÙ„ ...
}

# --- Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ ---

def analyze_text_robust(text):
    """
    Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„Ø°ÙƒÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬.
    """
    if not text: return []
    results = []
    processed_tests = set()
    text_lower = text.lower()
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙÙŠ Ø§Ù„Ù†Øµ ÙˆÙ…ÙˆØ§Ù‚Ø¹Ù‡Ø§
    found_numbers = [(m.group(1), m.start()) for m in re.finditer(r'(\d+\.?\d*)', text_lower)]
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙØ­ÙˆØµØ§Øª ÙˆÙ…ÙˆØ§Ù‚Ø¹Ù‡Ø§
    found_tests = []
    for key in KNOWLEDGE_BASE.keys():
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… \b Ù„Ø¶Ù…Ø§Ù† ØªØ·Ø§Ø¨Ù‚ Ø§Ù„ÙƒÙ„Ù…Ø© ÙƒØ§Ù…Ù„Ø©
        pattern = re.compile(rf'\b{key}\b', re.IGNORECASE)
        for match in pattern.finditer(text_lower):
            found_tests.append({'key': key, 'pos': match.end()})
            
    # ØªØ±ØªÙŠØ¨ Ø§Ù„ÙØ­ÙˆØµØ§Øª Ø­Ø³Ø¨ Ù…ÙˆÙ‚Ø¹Ù‡Ø§ ÙÙŠ Ø§Ù„Ù†Øµ
    found_tests.sort(key=lambda x: x['pos'])

    for test in found_tests:
        key = test['key']
        if key in processed_tests: continue
        
        best_candidate_val = None
        min_distance = float('inf')

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù‚Ø±Ø¨ Ø±Ù‚Ù… ÙŠØ£ØªÙŠ Ø¨Ø¹Ø¯ Ø§Ø³Ù… Ø§Ù„ÙØ­Øµ
        for num_val, num_pos in found_numbers:
            distance = num_pos - test['pos']
            if 0 < distance < min_distance:
                # ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø­Ø±Ù Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø±Ù‚Ù… (Ù„ØªØ¬Ù†Ø¨ Ø£Ø±Ù‚Ø§Ù… Ù…Ø«Ù„ x10^9)
                if num_pos + len(num_val) < len(text_lower) and text_lower[num_pos + len(num_val)].isalpha():
                    continue
                min_distance = distance
                best_candidate_val = num_val
        
        if best_candidate_val:
            try:
                value = float(best_candidate_val)
                details = KNOWLEDGE_BASE[key]
                low, high = details["range"]
                
                status = "Ø·Ø¨ÙŠØ¹ÙŠ"
                if value < low: status = "Ù…Ù†Ø®ÙØ¶"
                elif value > high: status = "Ù…Ø±ØªÙØ¹"
                
                results.append({
                    "name": details['name_ar'],
                    "value": value,
                    "status": status,
                    "recommendation": details.get(f"recommendation_{status.lower()}", ""),
                    "category": details.get("category", "Ø¹Ø§Ù…")
                })
                processed_tests.add(key)
            except (ValueError, KeyError):
                continue
    return results

def display_results(results):
    """
    Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¬Ù…Ø¹Ø© Ø­Ø³Ø¨ Ø§Ù„ÙØ¦Ø©.
    """
    if not results:
        st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø£ÙŠ ÙØ­ÙˆØµØ§Øª Ù…Ø¯Ø¹ÙˆÙ…Ø© ÙÙŠ Ø§Ù„ØªÙ‚Ø±ÙŠØ±.")
        return

    grouped = {}
    for res in results:
        cat = res.get("category", "Ø¹Ø§Ù…")
        if cat not in grouped:
            grouped[cat] = []
        grouped[cat].append(res)

    sorted_categories = sorted(grouped.keys())
    
    for category in sorted_categories:
        st.subheader(f"ğŸ“ {category}")
        for r in results:
            if r['category'] == category:
                status_color = "green" if r['status'] == 'Ø·Ø¨ÙŠØ¹ÙŠ' else "orange" if r['status'] == 'Ù…Ù†Ø®ÙØ¶' else "red"
                st.markdown(f"**{r['name']}**: {r['value']}  <span style='color:{status_color}; font-weight:bold;'>({r['status']})</span>", unsafe_allow_html=True)
                if r['recommendation']:
                    st.info(f"ğŸ’¡ {r['recommendation']}")
        st.markdown("---")

# (Ø¯Ø§Ù„Ø© get_ai_interpretation ÙˆØ¯Ø§Ù„Ø© plot_signal ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ)
def get_ai_interpretation(api_key, results):
    # ... (Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ø¯Ø§Ù„Ø© Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©) ...
    pass

def plot_signal(signal, title):
    # ... (Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ø¯Ø§Ù„Ø© Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©) ...
    pass

# --- Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„ØªØ·Ø¨ÙŠÙ‚ ---
st.title("âš•ï¸ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø·Ø¨ÙŠØ© Ø§Ù„Ø°ÙƒÙŠØ©")

st.sidebar.header("Ø§Ø®ØªØ± Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©")
mode = st.sidebar.radio(
    "Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:",
    ("ğŸ”¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ© (OCR)", "ğŸ©º Ù…Ø¯Ù‚Ù‚ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ø°ÙƒÙŠ", "ğŸ’“ Ù…Ø­Ù„Ù„ Ø¥Ø´Ø§Ø±Ø§Øª ECG")
)
st.sidebar.markdown("---")
api_key_input = st.sidebar.text_input("ğŸ”‘ Ø£Ø¯Ø®Ù„ Ù…ÙØªØ§Ø­ OpenAI API (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", type="password")

# --- Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¹Ø±Ø¶ Ø­Ø³Ø¨ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± ---

# 1. ÙˆØ¶Ø¹ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± (Ù…Ø¹ Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ù‡Ø¬ÙŠÙ†)
if mode == "ğŸ”¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ© (OCR)":
    st.header("ğŸ”¬ ØªØ­Ù„ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ø·Ø¨ÙŠ (ØµÙˆØ±Ø©)")
    uploaded_file = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØ±Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù‡Ù†Ø§", type=["png","jpg","jpeg"])
    
    if uploaded_file:
        file_bytes = uploaded_file.getvalue()
        text = ""
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø© Ø¨Ù€ Tesseract
        with st.spinner("Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©..."):
            try:
                text = pytesseract.image_to_string(Image.open(io.BytesIO(file_bytes)), lang='eng+ara')
                results = analyze_text_robust(text)
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Ø¬Ø§Ø­ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©
                if len(results) < 3:
                    st.warning("Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø© Ù„Ù… ØªØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ ÙƒØ§ÙÙŠØ©. Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…...")
                    text = "" # Ø¥ÙØ±Ø§Øº Ø§Ù„Ù†Øµ Ù„Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ù„Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©
                else:
                    st.success("ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø³Ø±ÙŠØ¹!")
            except Exception:
                text = "" # Ø£ÙŠ Ø®Ø·Ø£ ÙŠÙ†Ù‚Ù„Ù†Ø§ Ù„Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©

        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù‚ÙˆÙŠØ© Ø¨Ù€ EasyOCR (ÙÙ‚Ø· Ø¥Ø°Ø§ ÙØ´Ù„Øª Ø§Ù„Ø£ÙˆÙ„Ù‰)
        if not text:
            with st.spinner("Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… (EasyOCR) ÙŠØ­Ù„Ù„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¢Ù†... (Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ø¨Ø¹Ø¶ Ø§Ù„ÙˆÙ‚Øª)"):
                try:
                    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
                    img = Image.open(io.BytesIO(file_bytes)).convert('L')
                    img.thumbnail((1200, 1200), Image.Resampling.LANCZOS)
                    buffered = io.BytesIO()
                    img.save(buffered, format="PNG")
                    img_bytes_processed = buffered.getvalue()
                    
                    reader = load_ocr_models()
                    raw_results = reader.readtext(img_bytes_processed, detail=0, paragraph=True)
                    text = "\n".join(raw_results)
                    st.success("ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…!")
                except Exception as e:
                    st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙØ§Ø¯Ø­ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…: {e}")
                    text = None

        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        if text:
            with st.expander("ğŸ“„ Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬"):
                st.text_area("Ø§Ù„Ù†Øµ:", text, height=250)
            
            final_results = analyze_text_robust(text)
            display_results(final_results)
            
            # (Ø²Ø± Ø·Ù„Ø¨ Ø§Ù„ØªÙØ³ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„ Ù…Ù† GPT)
            # ...
        elif text is None:
            # Ù„Ø§ ØªÙØ¹Ù„ Ø´ÙŠØ¦Ù‹Ø§ØŒ ÙÙ‚Ø¯ ØªÙ… Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£ Ø¨Ø§Ù„ÙØ¹Ù„
            pass
        else:
            st.error("Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ø£ÙŠ Ù…Ù† Ø§Ù„Ù…Ø­Ø±ÙƒÙŠÙ† Ù…Ù† Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†Øµ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©.")

# 2. ÙˆØ¶Ø¹ Ù…Ø¯Ù‚Ù‚ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶
elif mode == "ğŸ©º Ù…Ø¯Ù‚Ù‚ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ø°ÙƒÙŠ":
    # ... (Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù‡Ø°Ø§ Ø§Ù„ÙˆØ¶Ø¹ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©) ...
    pass

# 3. ÙˆØ¶Ø¹ Ù…Ø­Ù„Ù„ Ø¥Ø´Ø§Ø±Ø§Øª ECG
elif mode == "ğŸ’“ Ù…Ø­Ù„Ù„ Ø¥Ø´Ø§Ø±Ø§Øª ECG":
    # ... (Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù‡Ø°Ø§ Ø§Ù„ÙˆØ¶Ø¹ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©) ...
    pass
