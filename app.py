import streamlit as st
import re
import io
from PIL import Image
import pytesseract
import pdfplumber
import pandas as pd
import cv2
import numpy as np
from pdf2image import convert_from_bytes
import joblib
import os

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(
    page_title="AI Medical Analyzer",
    page_icon="ğŸ©º",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ù„Ø¨ÙŠØ¦Ø© Streamlit Cloud ---
# ÙÙŠ Ø¨ÙŠØ¦Ø© Ù„ÙŠÙ†ÙƒØ³ØŒ Ù†Ø­ØªØ§Ø¬ Ø£Ø­ÙŠØ§Ù†Ù‹Ø§ Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø± ÙŠØ¯ÙˆÙŠÙ‹Ø§
pytesseract.pytesseract.tesseract_cmd = 'tesseract'
POPPLER_PATH = '/usr/bin' # Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø´Ø§Ø¦Ø¹ ÙÙŠ Ø¨ÙŠØ¦Ø§Øª Ù„ÙŠÙ†ÙƒØ³

# --- Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ­ÙˆØµØ§Øª ---
NORMAL_RANGES = {
    "wbc": {"range": (4000, 11000), "unit": "cells/mcL", "name_ar": "ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡"},
    "hemoglobin": {"range": (12.0, 17.5), "unit": "g/dL", "name_ar": "Ø§Ù„Ù‡ÙŠÙ…ÙˆØºÙ„ÙˆØ¨ÙŠÙ†"},
    "glucose": {"range": (70, 140), "unit": "mg/dL", "name_ar": "Ø§Ù„Ø¬Ù„ÙˆÙƒÙˆØ² (Ø§Ù„Ø³ÙƒØ±)"},
    "creatinine": {"range": (0.6, 1.3), "unit": "mg/dL", "name_ar": "Ø§Ù„ÙƒØ±ÙŠØ§ØªÙŠÙ†ÙŠÙ†"},
    "vitamin_d": {"range": (30, 100), "unit": "ng/mL", "name_ar": "ÙÙŠØªØ§Ù…ÙŠÙ† D"},
    "crp": {"range": (0, 5), "unit": "mg/L", "name_ar": "Ø¨Ø±ÙˆØªÙŠÙ† Ø³ÙŠ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ (CRP)"},
}

ALIASES = {
    "blood sugar": "glucose",
    "hb": "hemoglobin",
    "sugar": "glucose"
}

# --- ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ ---
@st.cache_resource
def load_model():
    # Ø³Ù†Ù‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ÙˆÙ‡Ù…ÙŠ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§
    model_path = "symptom_checker_model.joblib"
    if not os.path.exists(model_path):
        st.warning("Model file not found. Creating a dummy model.")
        # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ‡Ù…ÙŠ Ø¨Ø³ÙŠØ· (ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡ Ø¨Ù†Ù…ÙˆØ°Ø¬ Ø­Ù‚ÙŠÙ‚ÙŠ Ù„Ø§Ø­Ù‚Ù‹Ø§)
        from sklearn.dummy import DummyClassifier
        dummy_model = DummyClassifier(strategy="most_frequent")
        # ØªØ¯Ø±ÙŠØ¨ ÙˆÙ‡Ù…ÙŠ
        dummy_model.fit([[0]], [0])
        joblib.dump(dummy_model, model_path)
        return dummy_model
        
    try:
        model = joblib.load(model_path)
        return model
    except Exception as e:
        st.error(f"Error loading model: {e}")
        return None

model = load_model()

# --- Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ù‚Ø¨Ù„ OCR ---
def preprocess_image(img):
    try:
        gray = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2GRAY)
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªÙ†Ø¹ÙŠÙ… Ù„Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙˆÙŠØ´
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹ØªØ¨Ø© Ù…ØªÙƒÙŠÙØ© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø£ÙØ¶Ù„ Ù…Ø¹ Ø¥Ø¶Ø§Ø¡Ø© Ù…Ø®ØªÙ„ÙØ©
        thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
        return Image.fromarray(thresh)
    except Exception as e:
        st.warning(f"Could not preprocess image: {e}")
        return img # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙÙŠ Ø­Ø§Ù„Ø© Ø­Ø¯ÙˆØ« Ø®Ø·Ø£

# --- Ù‚Ø±Ø§Ø¡Ø© ØµÙˆØ±Ø© ---
def extract_text_from_image(file_bytes):
    try:
        img = Image.open(io.BytesIO(file_bytes))
        img_processed = preprocess_image(img)
        text = pytesseract.image_to_string(img_processed, lang="eng+ara")
        return text, None
    except Exception as e:
        return None, f"OCR Error: {e}"

# --- Ù‚Ø±Ø§Ø¡Ø© PDF (Ù†Øµ + ØµÙˆØ±) ---
def extract_text_from_pdf(file_bytes):
    texts = []
    errors = []
    try:
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†Øµ Ù…Ø¨Ø§Ø´Ø±Ø© Ø£ÙˆÙ„Ø§Ù‹
        with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    texts.append(page_text)

        # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØµØŒ ÙÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù† Ø§Ù„Ù€ PDF Ù‡Ùˆ ØµÙˆØ±Ø©
        if not texts or not "".join(texts).strip():
            st.info("PDF seems to be an image. Converting pages to images for OCR...")
            pages = convert_from_bytes(file_bytes, poppler_path=POPPLER_PATH)
            for i, page_img in enumerate(pages):
                try:
                    page_img_processed = preprocess_image(page_img)
                    txt = pytesseract.image_to_string(page_img_processed, lang="eng+ara")
                    texts.append(f"\n--- OCR from Page {i+1} ---\n{txt}")
                except Exception as e:
                    errors.append(f"Error OCR page {i+1}: {e}")
    except Exception as e:
        return None, f"PDF Error: {e}"

    return "\n".join(texts), (errors if errors else None)

# --- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·Ø¨ÙŠØ© ---
def analyze_text(text):
    results = []
    if not text:
        return results
    text_lower = text.lower()
    for key, details in NORMAL_RANGES.items():
        aliases = [k for k, v in ALIASES.items() if v == key]
        search_keys = [key] + aliases
        pattern = re.compile(rf"\b({'|'.join(search_keys)})\b\s*[:\-=]*\s*([0-9]+(?:\.[0-9]+)?)", re.IGNORECASE)
        matches = pattern.finditer(text_lower)
        for m in matches:
            try:
                value = float(m.group(2))
                
                # ØªØ¬Ù†Ø¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…ÙƒØ±Ø±Ø©
                if any(d['Ø§Ù„ÙØ­Øµ'] == details["name_ar"] for d in results):
                    continue

                low, high = details["range"]
                status = "Normal"
                if value < low:
                    status = "Low"
                elif value > high:
                    status = "High"
                results.append({
                    "Ø§Ù„ÙØ­Øµ": details["name_ar"],
                    "Ø§Ù„Ù‚ÙŠÙ…Ø©": value,
                    "Ø§Ù„ÙˆØ­Ø¯Ø©": details["unit"],
                    "Ø§Ù„Ø­Ø§Ù„Ø©": status,
                    "Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ": f"{low}-{high}"
                })
                break # Ù†ÙƒØªÙÙŠ Ø¨Ø£ÙˆÙ„ Ù†ØªÙŠØ¬Ø© Ù„Ù„ÙØ­Øµ
            except:
                continue
    return results

# --- ÙˆØ§Ø¬Ù‡Ø© ---
st.title("ğŸ©º Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø·Ø¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ (Ù†Ø³Ø®Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ©)")

st.sidebar.header("ğŸ“Œ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©")
mode = st.sidebar.radio("Ø§Ø®ØªØ± Ø§Ù„Ø®Ø¯Ù…Ø©:", ["ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ©", "Ø§Ø³ØªØ´Ø§Ø±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶"])

if mode == "ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ©":
    st.header("ğŸ”¬ ØªØ­Ù„ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ø·Ø¨ÙŠ (PDF Ø£Ùˆ ØµÙˆØ±Ø©)")
    uploaded_file = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„Ù", type=["png","jpg","jpeg","pdf"])
    if uploaded_file:
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„... Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ù‚Ø¯ ØªØ³ØªØºØ±Ù‚ Ø¨Ø¹Ø¶ Ø§Ù„ÙˆÙ‚Øª."):
            file_bytes = uploaded_file.getvalue()
            text, err = (extract_text_from_pdf(file_bytes) if "pdf" in uploaded_file.type
                         else extract_text_from_image(file_bytes))
            if err: st.error(err)
            if text:
                st.subheader("ğŸ“„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬:")
                st.text_area("Extracted Text", text, height=200)
                results = analyze_text(text)
                if results:
                    df = pd.DataFrame(results)
                    st.subheader("ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„:")
                    
                    def color_status(row):
                        if row['Ø§Ù„Ø­Ø§Ù„Ø©'] == 'High':
                            return ['background-color: #ffebee'] * len(row)
                        elif row['Ø§Ù„Ø­Ø§Ù„Ø©'] == 'Low':
                            return ['background-color: #fff8e1'] * len(row)
                        else:
                            return [''] * len(row)

                    st.dataframe(df.style.apply(color_status, axis=1), use_container_width=True)
                    
                    abnormal = df[df["Ø§Ù„Ø­Ø§Ù„Ø©"] != "Normal"]
                    if not abnormal.empty:
                        st.error("âš ï¸ ÙŠÙˆØ¬Ø¯ ÙØ­ÙˆØµØ§Øª ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠØ© ØªØ­ØªØ§Ø¬ Ù…ØªØ§Ø¨Ø¹Ø© Ø·Ø¨ÙŠØ©.")
                else:
                    st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø£ÙŠ ÙØ­ÙˆØµØ§Øª ÙÙŠ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬.")
            else:
                st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙŠ Ù†Øµ Ù…Ù† Ø§Ù„Ù…Ù„Ù. Ù‚Ø¯ ØªÙƒÙˆÙ† Ø§Ù„ØµÙˆØ±Ø© ØºÙŠØ± ÙˆØ§Ø¶Ø­Ø© Ø£Ùˆ Ø§Ù„Ù…Ù„Ù ÙØ§Ø±ØºÙ‹Ø§.")

elif mode == "Ø§Ø³ØªØ´Ø§Ø±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶":
    st.header("ğŸ’¬ Ø§Ø³ØªØ´Ø§Ø±Ø© Ø£ÙˆÙ„ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶")
    symptoms = st.text_area("ğŸ“ ØµÙ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ù‡Ù†Ø§ Ø¨Ø§Ù„ØªÙØµÙŠÙ„:", height=150)
    if st.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶"):
        if symptoms:
            if model:
                st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø¨Ù†Ø¬Ø§Ø­.")
                # Ø¨Ù…Ø§ Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ‡Ù…ÙŠØŒ Ø³Ù†Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© ØªÙˆØ¶ÙŠØ­ÙŠØ©
                st.info("âš ï¸ Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù‡Ùˆ Ù†Ù…ÙˆØ°Ø¬ ØªØ¬Ø±ÙŠØ¨ÙŠ. ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ØŒ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ù…Ø¯Ø®Ù„Ø© Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„ØµØ­ÙŠØ©.")
                st.write(f"Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ù…Ø¯Ø®Ù„Ø©: {symptoms}")
            else:
                st.error("ğŸš¨ Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ (symptom_checker_model.joblib).")
        else:
            st.warning("ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø£ÙˆÙ„Ø§Ù‹.")

st.sidebar.markdown("---")
st.sidebar.info("ØªÙ… Ø§Ù„ØªØ·ÙˆÙŠØ± Ø¨ÙˆØ§Ø³Ø·Ø© ÙØ±ÙŠÙ‚ Manus Ø¨Ø§Ù„ØªØ¹Ø§ÙˆÙ† Ù…Ø¹ Ø§Ù„Ù…Ø·ÙˆØ± Ø§Ù„Ù…Ø¨Ø¯Ø¹: Ø£Ù†Øª!")
