import streamlit as st
import re
import io
import numpy as np
from PIL import Image
import easyocr

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(
    page_title="Medical Report Analyzer",
    page_icon="ğŸ”¬",
    layout="centered", # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ®Ø·ÙŠØ· Ø§Ù„Ù…Ø±ÙƒØ²ÙŠ Ù„ØªØ¨Ø³ÙŠØ· Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
    initial_sidebar_state="collapsed"
)

# --- ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ OCR (Ù…Ø¹ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª) ---
@st.cache_resource
def load_ocr_model():
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ÙÙ‚Ø· Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¯Ù‚Ø© ÙˆÙ…Ù†Ø¹ Ø§Ù„ØªØ´ÙˆÙŠØ´
    return easyocr.Reader(['en'])

# --- Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø±ÙƒØ²Ø© ---
KNOWLEDGE_BASE = {
    "wbc": {"name_ar": "ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡", "aliases": ["w.b.c", "white blood cells"], "range": (4.0, 11.0), "category": "ÙØ­Øµ Ø§Ù„Ø¯Ù…"},
    "rbc": {"name_ar": "ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø­Ù…Ø±Ø§Ø¡", "aliases": ["r.b.c", "red blood cells"], "range": (4.1, 5.9), "category": "ÙØ­Øµ Ø§Ù„Ø¯Ù…"},
    "hemoglobin": {"name_ar": "Ø§Ù„Ù‡ÙŠÙ…ÙˆØºÙ„ÙˆØ¨ÙŠÙ†", "aliases": ["hb", "hgb"], "range": (13.0, 18.0), "category": "ÙØ­Øµ Ø§Ù„Ø¯Ù…"},
    "platelets": {"name_ar": "Ø§Ù„ØµÙØ§Ø¦Ø­ Ø§Ù„Ø¯Ù…ÙˆÙŠØ©", "aliases": ["plt"], "range": (150, 450), "category": "ÙØ­Øµ Ø§Ù„Ø¯Ù…"},
    "color": {"name_ar": "Ù„ÙˆÙ† Ø§Ù„Ø¨ÙˆÙ„", "aliases": ["colour"], "range": (0, 0), "category": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙˆÙ„"},
    "appearance": {"name_ar": "Ø¹ÙƒØ§Ø±Ø© Ø§Ù„Ø¨ÙˆÙ„", "aliases": ["clarity"], "range": (0, 0), "category": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙˆÙ„"},
    "ph": {"name_ar": "Ø­Ù…ÙˆØ¶Ø© Ø§Ù„Ø¨ÙˆÙ„ (pH)", "aliases": ["p.h", "p h"], "range": (4.5, 8.0), "category": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙˆÙ„"},
    "sg": {"name_ar": "Ø§Ù„ÙƒØ«Ø§ÙØ© Ø§Ù„Ù†ÙˆØ¹ÙŠØ©", "aliases": ["specific gravity", "gravity"], "range": (1.005, 1.030), "category": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙˆÙ„"},
    "leukocytes": {"name_ar": "ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡ (Ø¨ÙˆÙ„)", "aliases": ["leukocyte", "leu"], "range": (0, 0), "category": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙˆÙ„"},
    "pus": {"name_ar": "Ø®Ù„Ø§ÙŠØ§ Ø§Ù„ØµØ¯ÙŠØ¯", "aliases": ["pus cells"], "range": (0, 5), "category": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙˆÙ„"},
    "rbcs": {"name_ar": "ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø­Ù…Ø±Ø§Ø¡ (Ø¨ÙˆÙ„)", "aliases": ["rbc's", "red blood cells", "blood"], "range": (0, 2), "category": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙˆÙ„"},
}

# --- Ø¯Ø§Ù„Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ (ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ) ---
def analyze_text_robust(text):
    if not text: return []
    results = []
    text_lower = text.lower()
    # ... (Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ø¯Ø§Ù„Ø© Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©ØŒ ÙˆÙ‡Ùˆ ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ø¬ÙŠØ¯)
    found_numbers = [(m.group(1), m.start()) for m in re.finditer(r'(\d+\.?\d*)', text_lower)]
    found_tests = []
    for key, details in KNOWLEDGE_BASE.items():
        search_terms = [key] + details.get("aliases", [])
        for term in search_terms:
            pattern = re.compile(rf'\b{re.escape(term)}\b', re.IGNORECASE)
            for match in pattern.finditer(text_lower):
                found_tests.append({'key': key, 'pos': match.end()})
                break
            else: continue
            break
    found_tests.sort(key=lambda x: x['pos'])
    unique_found_keys = []
    for test in found_tests:
        if test['key'] not in [t['key'] for t in unique_found_keys]:
             unique_found_keys.append(test)
    for test in unique_found_keys:
        key = test['key']
        best_candidate_val = None
        min_distance = float('inf')
        for num_val, num_pos in found_numbers:
            distance = num_pos - test['pos']
            if 0 < distance < 50:
                if num_pos + len(num_val) < len(text_lower) and text_lower[num_pos + len(num_val)].isalpha():
                    continue
                min_distance = distance
                best_candidate_val = num_val
                break
        if best_candidate_val:
            try:
                value = float(best_candidate_val)
                details = KNOWLEDGE_BASE[key]
                low, high = details["range"]
                status = "Ø·Ø¨ÙŠØ¹ÙŠ"
                if value < low: status = "Ù…Ù†Ø®ÙØ¶"
                elif value > high: status = "Ù…Ø±ØªÙØ¹"
                results.append({
                    "name": details['name_ar'], "value": value, "status": status,
                    "category": details.get("category", "Ø¹Ø§Ù…")
                })
            except (ValueError, KeyError):
                continue
    return results

# --- Ø¯Ø§Ù„Ø© Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Ù…Ø¨Ø³Ø·Ø©) ---
def display_results(results):
    if not results:
        st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø£ÙŠ ÙØ­ÙˆØµØ§Øª Ù…Ø¯Ø¹ÙˆÙ…Ø© ÙÙŠ Ø§Ù„ØªÙ‚Ø±ÙŠØ±.")
        return
    
    st.subheader("ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„")
    for r in results:
        status_color = "green" if r['status'] == 'Ø·Ø¨ÙŠØ¹ÙŠ' else "orange" if r['status'] == 'Ù…Ù†Ø®ÙØ¶' else "red"
        st.markdown(f"**{r['name']}**: {r['value']}  <span style='color:{status_color}; font-weight:bold;'>({r['status']})</span>", unsafe_allow_html=True)
    st.markdown("---")
    st.warning("Ù‡Ø°Ø§ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù‡Ùˆ Ù„Ø£ØºØ±Ø§Ø¶ Ø¥Ø±Ø´Ø§Ø¯ÙŠØ© ÙÙ‚Ø· ÙˆÙ„Ø§ ÙŠØºÙ†ÙŠ Ø¹Ù† Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ø·Ø¨ÙŠØ¨ Ø§Ù„Ù…Ø®ØªØµ.")

# --- Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„ØªØ·Ø¨ÙŠÙ‚ (Ù…Ø¨Ø³Ø·Ø© ÙˆÙ…Ø±ÙƒØ²Ø©) ---
st.title("ğŸ”¬ Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠ Ù„Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ©")
st.info("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© ÙˆØ§Ø¶Ø­Ø© Ù„ØªÙ‚Ø±ÙŠØ±Ùƒ Ø§Ù„Ø·Ø¨ÙŠ (ÙØ­Øµ Ø§Ù„Ø¯Ù… Ø£Ùˆ Ø§Ù„Ø¨ÙˆÙ„) ÙˆØ³ÙŠÙ‚ÙˆÙ… Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¨ØªØ­Ù„ÙŠÙ„Ù‡Ø§.")

uploaded_file = st.file_uploader("ğŸ“‚ Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ±...", type=["png", "jpg", "jpeg"], label_visibility="collapsed")

if uploaded_file:
    file_bytes = uploaded_file.getvalue()
    text = None
    
    with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©... (Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ù‡Ø°Ø§ Ø¨Ø¹Ø¶ Ø§Ù„ÙˆÙ‚Øª Ù„Ù„ØµÙˆØ± Ø§Ù„ÙƒØ¨ÙŠØ±Ø©)"):
        try:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¨ÙƒÙØ§Ø¡Ø©
            img = Image.open(io.BytesIO(file_bytes))
            MAX_SIZE = (1500, 1500)
            img.thumbnail(MAX_SIZE, Image.Resampling.LANCZOS)
            
            img_processed = img.convert('L')
            
            buffered = io.BytesIO()
            img_processed.save(buffered, format="PNG")
            img_bytes_processed = buffered.getvalue()
            
            st.info(f"ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø¬Ø§Ø­. (Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯: {len(img_bytes_processed) / 1024:.1f} KB)")
            
            # ØªØ´ØºÙŠÙ„ EasyOCR
            reader = load_ocr_model()
            raw_results = reader.readtext(img_bytes_processed, detail=0, paragraph=True)
            text = "\n".join(raw_results)
            st.success("ØªÙ…Øª Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©!")

        except Exception as e:
            st.error("Ø­Ø¯Ø« Ø®Ø·Ø£ ÙØ§Ø¯Ø­ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©.")
            st.exception(e) # Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£ Ø§Ù„ÙƒØ§Ù…Ù„Ø©
            text = None

    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    if text:
        with st.expander("ğŸ“„ Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ (Ù„Ù„ØªØ¯Ù‚ÙŠÙ‚)"):
            st.text_area("Ø§Ù„Ù†Øµ:", text, height=200)
        
        final_results = analyze_text_robust(text)
        display_results(final_results)

