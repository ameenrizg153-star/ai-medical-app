# app.py
import streamlit as st
import re
import io
from PIL import Image
import pytesseract
import pdfplumber
import pandas as pd
import matplotlib.pyplot as plt
import cv2
import numpy as np
from pdf2image import convert_from_bytes
import joblib
import os
from datetime import datetime
from fpdf import FPDF
import base64

# ---------- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ----------
st.set_page_config(page_title="AI Medical Analyzer", page_icon="ğŸ©º", layout="wide")

# ---------- Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ÙØ­ÙˆØµØ§Øª (Ù…ÙˆØ³Ø¹Ø©: Ø£Ø¶Ù Ø£Ùˆ Ø¹Ø¯Ù„ ÙƒÙ…Ø§ ØªØ±ÙŠØ¯) ----------
NORMAL_RANGES = {
    # CBC
    "wbc": {"range": (4000, 11000), "unit": "cells/mcL", "name_ar": "ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡"},
    "rbc": {"range": (4.0, 6.0), "unit": "mil/mcL", "name_ar": "ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø­Ù…Ø±Ø§Ø¡"},
    "hemoglobin": {"range": (12.0, 17.5), "unit": "g/dL", "name_ar": "Ø§Ù„Ù‡ÙŠÙ…ÙˆØºÙ„ÙˆØ¨ÙŠÙ†"},
    "hematocrit": {"range": (36, 50), "unit": "%", "name_ar": "Ø§Ù„Ù‡ÙŠÙ…Ø§ØªÙˆÙƒØ±ÙŠØª"},
    "platelets": {"range": (150000, 450000), "unit": "cells/mcL", "name_ar": "Ø§Ù„ØµÙØ§Ø¦Ø­ Ø§Ù„Ø¯Ù…ÙˆÙŠØ©"},
    "mcv": {"range": (80, 100), "unit": "fL", "name_ar": "Ù…ØªÙˆØ³Ø· Ø­Ø¬Ù… Ø§Ù„ÙƒØ±ÙŠØ©"},
    "mch": {"range": (27, 33), "unit": "pg", "name_ar": "Ù…ØªÙˆØ³Ø· Ù‡ÙŠÙ…ÙˆØºÙ„ÙˆØ¨ÙŠÙ† Ø§Ù„ÙƒØ±ÙŠØ©"},
    "mchc": {"range": (32, 36), "unit": "g/dL", "name_ar": "ØªØ±ÙƒÙŠØ² Ù‡ÙŠÙ…ÙˆØºÙ„ÙˆØ¨ÙŠÙ† Ø§Ù„ÙƒØ±ÙŠØ©"},
    "rdw": {"range": (11.5, 14.5), "unit": "%", "name_ar": "Ø¹Ø±Ø¶ ØªÙˆØ²ÙŠØ¹ ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø­Ù…Ø±Ø§Ø¡"},
    # Metabolic / Chemistry
    "glucose": {"range": (70, 140), "unit": "mg/dL", "name_ar": "Ø§Ù„Ø¬Ù„ÙˆÙƒÙˆØ² (Ø§Ù„Ø³ÙƒØ±)"},
    "bun": {"range": (7, 20), "unit": "mg/dL", "name_ar": "Ù†ÙŠØªØ±ÙˆØ¬ÙŠÙ† ÙŠÙˆØ±ÙŠØ§ Ø§Ù„Ø¯Ù…"},
    "creatinine": {"range": (0.6, 1.3), "unit": "mg/dL", "name_ar": "Ø§Ù„ÙƒØ±ÙŠØ§ØªÙŠÙ†ÙŠÙ†"},
    "egfr": {"range": (60, 120), "unit": "mL/min/1.73m2", "name_ar": "Ù…Ø¹Ø¯Ù„ ØªØ±Ø´ÙŠØ­ Ø§Ù„ÙƒÙ„Ù‰ (eGFR)"},
    "sodium": {"range": (135, 145), "unit": "mEq/L", "name_ar": "Ø§Ù„ØµÙˆØ¯ÙŠÙˆÙ…"},
    "potassium": {"range": (3.5, 5.0), "unit": "mEq/L", "name_ar": "Ø§Ù„Ø¨ÙˆØªØ§Ø³ÙŠÙˆÙ…"},
    # Liver
    "ast": {"range": (10, 40), "unit": "U/L", "name_ar": "Ø¥Ù†Ø²ÙŠÙ… AST"},
    "alt": {"range": (7, 56), "unit": "U/L", "name_ar": "Ø¥Ù†Ø²ÙŠÙ… ALT"},
    "alp": {"range": (44, 147), "unit": "U/L", "name_ar": "Ø¥Ù†Ø²ÙŠÙ… ALP"},
    "ggt": {"range": (9, 48), "unit": "U/L", "name_ar": "Ø¥Ù†Ø²ÙŠÙ… GGT"},
    "bilirubin_total": {"range": (0.1, 1.2), "unit": "mg/dL", "name_ar": "Ø§Ù„Ø¨ÙŠÙ„ÙŠØ±ÙˆØ¨ÙŠÙ† Ø§Ù„ÙƒÙ„ÙŠ"},
    # Lipids
    "cholesterol": {"range": (0, 200), "unit": "mg/dL", "name_ar": "Ø§Ù„ÙƒÙˆÙ„ÙŠØ³ØªØ±ÙˆÙ„ Ø§Ù„ÙƒÙ„ÙŠ"},
    "triglycerides": {"range": (0, 150), "unit": "mg/dL", "name_ar": "Ø§Ù„Ø¯Ù‡ÙˆÙ† Ø§Ù„Ø«Ù„Ø§Ø«ÙŠØ©"},
    "hdl": {"range": (40, 60), "unit": "mg/dL", "name_ar": "Ø§Ù„ÙƒÙˆÙ„ÙŠØ³ØªØ±ÙˆÙ„ Ø§Ù„Ø¬ÙŠØ¯"},
    "ldl": {"range": (0, 100), "unit": "mg/dL", "name_ar": "Ø§Ù„ÙƒÙˆÙ„ÙŠØ³ØªØ±ÙˆÙ„ Ø§Ù„Ø¶Ø§Ø±"},
    # Vitamins / markers
    "vitamin_d": {"range": (30, 100), "unit": "ng/mL", "name_ar": "ÙÙŠØªØ§Ù…ÙŠÙ† D"},
    "vitamin_b12": {"range": (200, 900), "unit": "pg/mL", "name_ar": "ÙÙŠØªØ§Ù…ÙŠÙ† B12"},
    "ferritin": {"range": (30, 400), "unit": "ng/mL", "name_ar": "Ø§Ù„ÙÙŠØ±ÙŠØªÙŠÙ†"},
    "crp": {"range": (0, 5), "unit": "mg/L", "name_ar": "Ø¨Ø±ÙˆØªÙŠÙ† Ø³ÙŠ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ (CRP)"},
    "esr": {"range": (0, 20), "unit": "mm/hr", "name_ar": "Ù…Ø¹Ø¯Ù„ ØªØ±Ø³ÙŠØ¨ ÙƒØ±Ø§Øª Ø§Ù„Ø¯Ù… (ESR)"},
    "troponin": {"range": (0, 0.04), "unit": "ng/mL", "name_ar": "Ø§Ù„ØªØ±ÙˆØ¨ÙˆÙ†ÙŠÙ†"},
}

# --- Ø§Ø®ØªØµØ§Ø±Ø§Øª ÙˆØ£Ø³Ù…Ø§Ø¡ Ø¨Ø¯ÙŠÙ„Ø© Ù„ØªØ³Ù‡ÙŠÙ„ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù†Øµ ---
ALIASES = {
    "blood sugar": "glucose", "sugar": "glucose", "hb": "hemoglobin",
    "wbc count": "wbc", "platelet count": "platelets", "creatinine level": "creatinine",
    "pus cells": "pus_cells", "vit d": "vitamin_d", "b12": "vitamin_b12",
    "b12 level": "vitamin_b12", "hct": "hematocrit", "hgb": "hemoglobin"
}

# ---------- Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ù‚Ø¨Ù„ OCR ----------
def preprocess_image(img):
    """ØªØ·Ø¨ÙŠØ¹ Ø§Ù„ØµÙˆØ±Ø© ÙˆØªØ­Ø³ÙŠÙ†Ù‡Ø§ Ù‚Ø¨Ù„ OCR"""
    try:
        arr = np.array(img)
        if arr.ndim == 3:
            gray = cv2.cvtColor(arr, cv2.COLOR_RGB2GRAY)
        else:
            gray = arr
        # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ¨Ø§ÙŠÙ† ÙˆØ§Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
        gray = cv2.GaussianBlur(gray, (3,3), 0)
        # adaptive threshold to better handle different lighting
        thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                       cv2.THRESH_BINARY,11,2)
        return Image.fromarray(thresh)
    except Exception:
        return img

# ---------- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Øµ Ù…Ù† ØµÙˆØ±Ø© (Ù…Ù„Ù ØµÙˆØ±) ----------
def extract_text_from_image(file_bytes):
    try:
        img = Image.open(io.BytesIO(file_bytes)).convert("RGB")
        img = preprocess_image(img)
        text = pytesseract.image_to_string(img, lang='eng+ara')
        return text, None
    except Exception as e:
        return None, f"OCR Error: {e}"

# ---------- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Øµ Ù…Ù† PDF: ÙŠØ¯Ø¹Ù… Ù†Øµ + ØµÙØ­Ø§Øª Ù…Ù…Ø³ÙˆØ­Ø© Ø¶ÙˆØ¦ÙŠØ§Ù‹ ----------
def extract_text_from_pdf(file_bytes):
    texts = []
    errors = []
    try:
        # Ø£ÙˆÙ„ Ù…Ø­Ø§ÙˆÙ„Ø©: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Øµ ÙØ¹Ù„ÙŠ Ù…Ù† PDF
        with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    texts.append(page_text)
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø­ØµÙ‘Ù„ Ù†Øµ (Ø£Ùˆ Ù†Ø±ÙŠØ¯ Ø£ÙŠØ¶Ø§Ù‹ Ø§Ù„Ù€ OCR Ù„Ù„ØµÙˆØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©)
        # Ù†Ø­ÙˆÙ„ ØµÙØ­Ø§Øª PDF Ø¥Ù„Ù‰ ØµÙˆØ± ÙˆÙ†Ø¹Ù…Ù„ OCR Ù„ÙƒÙ„ ØµÙØ­Ø©
        pages = convert_from_bytes(file_bytes)
        for i, page_img in enumerate(pages):
            try:
                page_img = page_img.convert("RGB")
                page_img = preprocess_image(page_img)
                txt = pytesseract.image_to_string(page_img, lang='eng+ara')
                if txt and txt.strip():
                    texts.append(txt)
            except Exception as e:
                errors.append(f"Page {i+1} OCR error: {e}")
    except Exception as e:
        return None, f"PDF Error: {e}"
    return "\n".join(texts), (errors if errors else None)

# ---------- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙØ­ÙˆØµØ§Øª ÙˆØ§Ù„Ù‚ÙŠÙÙ… ----------
def analyze_text(text):
    results = []
    if not text:
        return results
    text_lower = text.lower()

    # Ù€Ù€ Ù‚Ø§Ø¹Ø¯Ø©: Ù†Ø¨Ø­Ø« Ø¹Ù† Ø§Ø³Ù… Ø§Ù„ÙØ­Øµ Ø£Ùˆ Ø§Ø®ØªØµØ§Ø±Ù‡ Ù…ØªØ¨ÙˆØ¹Ù‹Ø§ Ø¨Ù‚ÙŠÙ…Ø© Ø±Ù‚Ù…ÙŠØ©
    # Ù†Ù…Ø· Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø© ÙŠØ¯Ø¹Ù… Ø¹Ù„Ø§Ù…Ø§Øª Ù…Ø®ØªÙ„ÙØ©: ":" "-" "=" Ø£Ùˆ Ø­ØªÙ‰ ÙØ±Ø§Øº
    for key, details in NORMAL_RANGES.items():
        # ØµÙ†Ø¹ Ù…Ø¬Ù…ÙˆØ¹Ø© ÙƒÙ„Ù…Ø§Øª Ø¨Ø­Ø« (Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØŒ Ø§Ù„Ø§Ø®ØªØµØ§Ø±Ø§ØªØŒ Ø§Ù„Ø§Ø³Ù… Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¥Ù† ÙˆØ¬Ø¯)
        aliases = [k for k, v in ALIASES.items() if v == key]
        search_keys = [key] + aliases
        # escape each key for regex, allow underscores/spaces/dots
        search_pat = '|'.join([re.escape(k) for k in search_keys])
        # Ù†Ù…Ø· Ø±Ù‚Ù… ÙƒØ§Ù…Ù„ Ø£Ùˆ Ø¹Ø´Ø±ÙŠØŒ ÙˆØ§Ø¯Ù…Ø§Ù‹ Ù…Ø¹ Ø¹Ù„Ø§Ù…Ø© <= Ø£Ùˆ >= Ùˆ% Ø¥Ù† ÙˆØ¬Ø¯Øª
        pattern = re.compile(rf"({search_pat})\b[^\d\-+]*?([0-9]+(?:\.[0-9]+)?)", re.IGNORECASE)
        for m in pattern.finditer(text_lower):
            try:
                value = float(m.group(2))
            except:
                continue
            low, high = details["range"]
            status = "Normal"
            if value < low: status = "Low"
            elif value > high: status = "High"
            results.append({
                "key": key,
                "Ø§Ù„ÙØ­Øµ": details["name_ar"],
                "Ø§Ù„Ù‚ÙŠÙ…Ø©": value,
                "Ø§Ù„ÙˆØ­Ø¯Ø©": details["unit"],
                "Ø§Ù„Ø­Ø§Ù„Ø©": status,
                "Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ": f"{low} - {high}"
            })
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª (Ù†ÙØ³ Ø§Ù„Ø§Ø³Ù… ÙˆÙ†ÙØ³ Ø§Ù„Ù‚ÙŠÙ…Ø©)
    unique = []
    seen = set()
    for r in results:
        tup = (r["key"], r["Ø§Ù„Ù‚ÙŠÙ…Ø©"])
        if tup not in seen:
            unique.append(r)
            seen.add(tup)
    return unique

# ---------- Ù‚ÙˆØ§Ø¹Ø¯ ØªÙØ³ÙŠØ± Ø¨Ø³ÙŠØ·Ø© (Ù„ØªÙˆÙ„ÙŠØ¯ Ø´Ø±Ø­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©) ----------
EXPLANATION_TEMPLATES = {
    "hemoglobin": {
        "Low": "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù‡ÙŠÙ…ÙˆØºÙ„ÙˆØ¨ÙŠÙ† Ù…Ù†Ø®ÙØ¶. Ù‡Ø°Ø§ Ù‚Ø¯ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ ÙÙ‚Ø± Ø§Ù„Ø¯Ù…. ÙŠÙØ¶Ù„ ÙØ­Øµ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ÙÙŠØ±ÙŠØªÙŠÙ† ÙˆÙÙŠØªØ§Ù…ÙŠÙ† B12 ÙˆØ§Ù„Ø­Ø¯ÙŠØ¯.",
        "High": "Ø§Ù„Ù‡ÙŠÙ…ÙˆØºÙ„ÙˆØ¨ÙŠÙ† Ø£Ø¹Ù„Ù‰ Ù…Ù† Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ. Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø³Ø¨Ø¨Ù‡ Ø¬ÙØ§Ù Ø£Ùˆ Ø£Ø³Ø¨Ø§Ø¨ Ø£Ø®Ø±Ù‰Ø› Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø·Ø¨ÙŠØ¨."
    },
    "wbc": {
        "Low": "Ø§Ù†Ø®ÙØ§Ø¶ ÙÙŠ ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡. Ù‚Ø¯ ÙŠØ­Ø¯Ø« ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„ÙÙŠØ±ÙˆØ³Ø§Øª Ø£Ùˆ Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†Ø®Ø§Ø¹.",
        "High": "Ø§Ø±ØªÙØ§Ø¹ ÙÙŠ ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡. ØºØ§Ù„Ø¨Ù‹Ø§ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø¹Ø¯ÙˆÙ‰ Ø£Ùˆ Ø§Ù„ØªÙ‡Ø§Ø¨."
    },
    "creatinine": {
        "High": "Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„ÙƒØ±ÙŠØ§ØªÙŠÙ†ÙŠÙ† Ù‚Ø¯ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø¶Ø¹Ù ÙÙŠ ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ÙƒÙ„Ù‰. ÙŠÙØ¶Ù„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù‚ÙŠØ§Ø³ ÙˆÙ‚ÙŠØ§Ø³ eGFR."
    },
    "glucose": {
        "Low": "Ø§Ù†Ø®ÙØ§Ø¶ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø³ÙƒØ± ÙÙŠ Ø§Ù„Ø¯Ù…. Ø§Ù†ØªØ¨Ù‡ Ù„Ù„Ø£Ø¹Ø±Ø§Ø¶ Ù…Ø«Ù„ Ø§Ù„Ø¯ÙˆØ§Ø± ÙˆØ§Ù„Ø¶Ø¹Ù.",
        "High": "Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„Ø³ÙƒØ±. Ù‚Ø¯ ÙŠØ­ØªØ§Ø¬ ÙØ­Øµ Ø³ÙƒØ± ØµØ§Ø¦Ù… Ø£Ùˆ ÙƒÙ„ÙŠ Ù„ÙØ­Øµ Ø§Ù„Ø³ÙƒØ±ÙŠ."
    },
    "crp": {
        "High": "Ø§Ø±ØªÙØ§Ø¹ CRP ÙŠØ´ÙŠØ± Ù„ÙˆØ¬ÙˆØ¯ Ø§Ù„ØªÙ‡Ø§Ø¨ Ø­Ø§Ø¯ Ø£Ùˆ Ø¹Ø¯ÙˆÙ‰."
    }
}
def explain_result(entry):
    key = entry["key"]
    status = entry["Ø§Ù„Ø­Ø§Ù„Ø©"]
    templ = EXPLANATION_TEMPLATES.get(key, {})
    return templ.get(status, "Ø§Ù„Ù‚ÙŠÙ…Ø© Ø¶Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹." if status == "Normal" else "ØªÙØ³ÙŠØ± Ù…Ø¨Ø¯Ø¦ÙŠ: Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø·Ø¨ÙŠØ¨ Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙ‚ÙŠÙŠÙ….")

# ---------- ØªØ­Ù…ÙŠÙ„/Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ (Decision Tree Ø£Ùˆ Ø£ÙŠ joblib) ----------
MODEL_PATH = "symptom_checker_model.joblib"
model = None
model_info = None
if os.path.exists(MODEL_PATH):
    try:
        model = joblib.load(MODEL_PATH)
        model_info = f"Model loaded from {MODEL_PATH}"
    except Exception as e:
        model_info = f"Failed to load model: {e}"
else:
    model_info = "No trained model found. (Ø¶Ø¹ Ù…Ù„Ù symtom_checker_model.joblib ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù„ØªÙØ¹ÙŠÙ„Ù‡)"

# Ø¯Ø§Ù„Ø© ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ (Ø¥Ø°Ø§ ØªÙˆÙØ±)
def model_predict(symptom_features):
    """
    symptom_features: list/array/1D vector with same feature order used Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    ÙŠØ¬Ø¨ Ø£Ù† ØªØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨. Ù‡Ù†Ø§ Ù…Ø¬Ø±Ø¯ ØºÙ„Ø§Ù.
    """
    if model is None:
        return None, "Model not available"
    try:
        pred = model.predict([symptom_features])
        return pred[0], None
    except Exception as e:
        return None, f"Prediction error: {e}"

# ---------- ØªØµØ¯ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬: Excel Ùˆ PDF ----------
def create_excel_bytes(df: pd.DataFrame):
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name="Analysis")
        writer.save()
    buffer.seek(0)
    return buffer.getvalue()

def create_pdf_report(extracted_text, results_df, notes=""):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    pdf.cell(0, 8, "AI Medical Analyzer - ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„", ln=True, align="C")
    pdf.ln(4)
    pdf.set_font("Arial", size=10)
    pdf.cell(0, 6, f"Ø§Ù„ØªØ§Ø±ÙŠØ®: {datetime.now().strftime('%Y-%m-%d %H:%M')}", ln=True)
    pdf.ln(4)
    pdf.cell(0, 6, "Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† Ø§Ù„ØªÙ‚Ø±ÙŠØ±:", ln=True)
    pdf.multi_cell(0, 6, extracted_text[:5000])  # Ù†Ù‚ØµØ± Ù„Ù„Ø­Ø¬Ù…
    pdf.ln(4)
    pdf.cell(0,6, "Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„:", ln=True)
    pdf.ln(2)
    # Ø¬Ø¯ÙˆÙ„ Ø¨Ø³ÙŠØ·
    pdf.set_font("Arial", size=9)
    col_w = [60,30,30,30]  # ØªÙ‚Ø±ÙŠØ¨ÙŠØ©
    header = ["Ø§Ù„ÙØ­Øµ", "Ø§Ù„Ù‚ÙŠÙ…Ø©", "Ø§Ù„ÙˆØ­Ø¯Ø©", "Ø§Ù„Ø­Ø§Ù„Ø©"]
    for i,h in enumerate(header):
        pdf.cell(col_w[i],6,h,1,0,"C")
    pdf.ln()
    for _, row in results_df.iterrows():
        pdf.cell(col_w[0],6,str(row.get("Ø§Ù„ÙØ­Øµ","")),1,0)
        pdf.cell(col_w[1],6,str(row.get("Ø§Ù„Ù‚ÙŠÙ…Ø©","")),1,0)
        pdf.cell(col_w[2],6,str(row.get("Ø§Ù„ÙˆØ­Ø¯Ø©","")),1,0)
        pdf.cell(col_w[3],6,str(row.get("Ø§Ù„Ø­Ø§Ù„Ø©","")),1,0)
        pdf.ln()
    if notes:
        pdf.ln(4)
        pdf.cell(0,6,"Ù…Ù„Ø§Ø­Ø¸Ø§Øª:", ln=True)
        pdf.multi_cell(0,6,notes)
    return pdf.output(dest='S').encode('latin-1')

# ---------- Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© ----------
st.title("ğŸ©º AI Medical Analyzer - Ù…ØªÙƒØ§Ù…Ù„")

st.sidebar.header("Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©")
page = st.sidebar.radio("Ø§Ø®ØªØ±:", ["ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ©", "Ø§Ø³ØªØ´Ø§Ø±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶", "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"])

if page == "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬":
    st.header("Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
    st.write(model_info)
    if model:
        st.write("Model type:", type(model))
        st.write("Model supported predict example: ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªÙ…Ø±ÙŠØ± features Ø¨Ù†ÙØ³ ØªØ±ØªÙŠØ¨ Ø§Ù„ØªØ¯Ø±ÙŠØ¨")
    st.markdown("---")
    st.write("Ù…Ù„Ø§Ø­Ø¸Ø§Øª: Ø¥Ø°Ø§ Ø£Ø±Ø¯ØªØŒ Ø£Ø±Ø³Ù„ Ù„ÙŠ Ù…Ù„Ù `symptom_checker_model.joblib` ÙˆØ³Ø£Ø¶Ø¹Ù‡ ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ (Ø£Ùˆ Ø¶Ø¹ Ø¨Ù†ÙØ³Ùƒ ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù…Ø¬Ù„Ø¯).")

# ===== ØµÙØ­Ø©: ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ© =====
if page == "ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ©":
    st.header("ğŸ”¬ ØªØ­Ù„ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ø·Ø¨ÙŠ (ØµÙˆØ±Ø© Ø£Ùˆ PDF - ÙŠØ¯Ø¹Ù… Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ù…Ø³ÙˆØ­Ø©)")
    uploaded_file = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„ØªÙ‚Ø±ÙŠØ± (png/jpg/jpeg/pdf)", type=["png","jpg","jpeg","pdf"])
    add_manual_notes = st.checkbox("Ø£Ø¶Ù Ù…Ù„Ø§Ø­Ø¸Ø§Øª ÙŠØ¯ÙˆÙŠØ© Ù„Ù„ØªÙ‚Ø±ÙŠØ± (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")

    if add_manual_notes:
        user_notes = st.text_area("Ø£Ø¯Ø®Ù„ Ù…Ù„Ø§Ø­Ø¸ØªÙƒ Ù‡Ù†Ø§:", height=80)
    else:
        user_notes = ""

    if uploaded_file:
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ..."):
            file_bytes = uploaded_file.getvalue()
            if "pdf" in uploaded_file.type:
                text, err = extract_text_from_pdf(file_bytes)
            else:
                text, err = extract_text_from_image(file_bytes)

        if err:
            st.error(err)
        if text:
            st.subheader("ğŸ“„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬:")
            st.text_area("Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„:", text, height=220)

            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙØ­ÙˆØµØ§Øª
            results = analyze_text(text)
            if results:
                df = pd.DataFrame(results)
                # Ø²Ø± Ø§Ù„ØªØ±ØªÙŠØ¨: Ø¹Ø±Ø¶ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©/ØºÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹
                df_sorted = df.sort_values(by="Ø§Ù„Ø­Ø§Ù„Ø©", key=lambda s: s.map({'High':2,'Low':1,'Normal':0}), ascending=False)
                st.subheader("ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„:")
                # ØªÙ„ÙˆÙŠÙ† Ø§Ù„ØµÙÙˆÙ Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ù„Ø©
                def highlight_row(row):
                    if row["Ø§Ù„Ø­Ø§Ù„Ø©"] == "High":
                        return ['background-color: #ffebee']*len(row)
                    elif row["Ø§Ù„Ø­Ø§Ù„Ø©"] == "Low":
                        return ['background-color: #fff8e1']*len(row)
                    else:
                        return ['']*len(row)
                st.dataframe(df_sorted.style.apply(highlight_row, axis=1), use_container_width=True)

                # ØªÙØ³ÙŠØ±Ø§Øª Ù„ÙƒÙ„ Ù†ØªÙŠØ¬Ø©
                st.subheader("ğŸ“ ØªÙØ³ÙŠØ±Ø§Øª Ù…ÙˆØ¬Ø²Ø©:")
                for r in results:
                    expl = explain_result(r)
                    st.markdown(f"- **{r['Ø§Ù„ÙØ­Øµ']} ({r['Ø§Ù„Ù‚ÙŠÙ…Ø©']} {r['Ø§Ù„ÙˆØ­Ø¯Ø©']})**: {expl}")

                # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©
                abnormal = df[df["Ø§Ù„Ø­Ø§Ù„Ø©"] != "Normal"]
                if not abnormal.empty:
                    st.subheader("ğŸ“ˆ Ø§Ù„ÙØ­ÙˆØµØ§Øª ØºÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© (Ù…Ø®Ø·Ø·):")
                    fig, ax = plt.subplots(figsize=(7, max(2, 0.4*len(abnormal))))
                    ax.barh(abnormal["Ø§Ù„ÙØ­Øµ"], abnormal["Ø§Ù„Ù‚ÙŠÙ…Ø©"])
                    ax.set_xlabel("Ø§Ù„Ù‚ÙŠÙ…Ø©")
                    st.pyplot(fig)

                # ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Excel & PDF
                excel_bytes = create_excel_bytes(df_sorted)
                st.download_button("â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Excel)", data=excel_bytes,
                                   file_name="analysis_results.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

                pdf_bytes = create_pdf_report(text, df_sorted, notes=user_notes)
                st.download_button("â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± (PDF)", data=pdf_bytes,
                                   file_name="analysis_report.pdf", mime="application/pdf")

            else:
                st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø£ÙŠ ÙØ­ÙˆØµØ§Øª ÙˆØ§Ø¶Ø­Ø©. Ø­Ø§ÙˆÙ„ Ø±ÙØ¹ ØµÙˆØ±Ø© Ø£Ùˆ PDF Ø£Ùˆ Ø§ÙƒØªØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙŠØ¯ÙˆÙŠÙ‹Ø§.")
        else:
            st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Øµ Ù…Ù† Ø§Ù„Ù…Ù„Ù.")
    else:
        st.info("Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù„ØªØ¨Ø¯Ø£ Ø§Ù„ØªØ­Ù„ÙŠÙ„.")

# ===== ØµÙØ­Ø©: Ø§Ø³ØªØ´Ø§Ø±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ (Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªÙˆÙØ±) =====
elif page == "Ø§Ø³ØªØ´Ø§Ø±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶":
    st.header("ğŸ’¬ Ø§Ø³ØªØ´Ø§Ø±Ø© Ø£ÙˆÙ„ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶")
    st.markdown("Ø£Ø¯Ø®Ù„ ÙˆØµÙÙ‹Ø§ Ù„Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø«Ù… ÙŠÙ…ÙƒÙ†Ùƒ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ø¥Ù† ÙˆÙØ¬Ø¯ (ÙŠØ­ØªØ§Ø¬ Ù…ÙŠØ²Ø§Øª Ø¨ØµÙŠØºØ© Ø±Ù‚Ù…ÙŠØ©).")
    symptoms_text = st.text_area("ØµÙ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ù‡Ù†Ø§ (Ù†Øµ):", height=140)
    use_model = st.checkbox("Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ (Ù„Ùˆ Ù…ØªØ§Ø­)")

    # Ù„Ùˆ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù†Ø¯Ù‡ ØµÙØ§Øª Ø¬Ø§Ù‡Ø²Ø© Ù„ØªÙ…Ø±ÙŠØ±Ù‡Ø§ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
    feature_input = None
    if use_model:
        if model is None:
            st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¯Ø±Ø¨ ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯. Ø¶Ø¹ 'symptom_checker_model.joblib' Ø¨Ø§Ù„Ù…Ø¬Ù„Ø¯ Ù„ØªÙØ¹ÙŠÙ„Ù‡.")
        else:
            st.info("ÙŠØ¬Ø¨ Ø£Ù† ØªØ²ÙˆØ¯ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø¨Ù†ÙØ³ ØªØ±ØªÙŠØ¨ Ø§Ù„ØªØ¯Ø±ÙŠØ¨. Ø£Ø¯Ø®Ù„Ù‡Ø§ ÙƒÙ‚Ø§Ø¦Ù…Ø© Ø£Ø¹Ø¯Ø§Ø¯ Ù…ÙØµÙˆÙ„Ø© Ø¨ÙÙˆØ§ØµÙ„.")
            feat_str = st.text_input("Ø§Ø¯Ø®Ù„ Ù…ØµÙÙˆÙØ© Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª (Ù…Ø«Ø§Ù„: 1,0,0,23,...)")
            if feat_str:
                try:
                    feature_input = [float(x.strip()) for x in feat_str.split(",")]
                except:
                    st.error("ØµÙŠØºØ© Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª ØºÙŠØ± ØµØ­ÙŠØ­Ø©. ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ù…ÙØµÙˆÙ„Ø© Ø¨ÙØ§ØµÙ„Ø©.")

    if st.button("ØªØ­Ù„ÙŠÙ„"):
        if not symptoms_text and feature_input is None:
            st.error("Ø£Ø¯Ø®Ù„ Ø£Ø¹Ø±Ø§Ø¶Ù‹Ø§ Ø£Ùˆ ÙØ¹Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.")
        else:
            # ØªØ­Ù„ÙŠÙ„ Ù†ØµÙŠ Ø¨Ø³ÙŠØ· (Ù‚ÙˆØ§Ø¹Ø¯)
            RULE_KB = {
                "Ø­Ù…Ù‰": {"conds": {"Ø¹Ø¯ÙˆÙ‰": 0.8, "Ø§Ù†ÙÙ„ÙˆÙ†Ø²Ø§": 0.6}, "advice": ["Ù‚ÙØ³ Ø§Ù„Ø­Ø±Ø§Ø±Ø©", "Ø§Ø´Ø±Ø¨ Ø³ÙˆØ§Ø¦Ù„"]},
                "Ø³Ø¹Ø§Ù„": {"conds": {"Ø§Ù„ØªÙ‡Ø§Ø¨ Ù‚ØµØ¨ÙŠ": 0.5, "Ø§Ù†ÙÙ„ÙˆÙ†Ø²Ø§": 0.6}, "advice": ["ØªØ§Ø¨Ø¹ Ø¶ÙŠÙ‚ Ø§Ù„Ù†ÙØ³", "Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø·Ø¨ÙŠØ¨ Ø¥Ø°Ø§ Ø§Ø³ØªÙ…Ø±"]},
                "Ø£Ù„Ù… ØµØ¯Ø±": {"conds": {"Ø­Ø§Ù„Ø© Ù‚Ù„Ø¨ÙŠØ©": 0.9}, "advice": ["Ø§Ø·Ù„Ø¨ Ø±Ø¹Ø§ÙŠØ© Ø·Ø¨ÙŠØ© Ø¹Ø§Ø¬Ù„Ø© Ø¥Ø°Ø§ Ø§Ù„Ø£Ù„Ù… Ø´Ø¯ÙŠØ¯"]},
            }
            txt = symptoms_text.lower()
            cond_scores = {}
            advices = set()
            for kw, info in RULE_KB.items():
                if kw in txt:
                    for c,w in info["conds"].items():
                        cond_scores[c] = cond_scores.get(c,0)+w
                    for a in info["advice"]:
                        advices.add(a)

            st.subheader("Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙŠ:")
            if cond_scores:
                for c,s in cond_scores.items():
                    st.write(f"- {c} (Ø¯Ø±Ø¬Ø©: {s:.2f})")
            else:
                st.write("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø·Ø§Ø¨Ù‚Ø© ÙˆØ§Ø¶Ø­Ø© ÙÙŠ Ù‚ÙˆØ§Ø¹Ø¯Ù†Ø§ Ø§Ù„Ø¨Ø³ÙŠØ·Ø©.")

            if advices:
                st.subheader("Ù†ØµØ§Ø¦Ø­ Ø£ÙˆÙ„ÙŠØ©:")
                for a in advices:
                    st.write(f"- {a}")

            # Ø¥Ø°Ø§ ÙˆÙØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù…ÙŠØ²Ø§Øª ÙˆÙ†Ù…ÙˆØ°Ø¬ Ù…ØªÙˆÙØ± -> Ø§Ø³ØªØ®Ø¯Ù…Ù‡
            if feature_input and model is not None:
                pred, err = model_predict(feature_input)
                if err:
                    st.error(err)
                else:
                    st.subheader("Ù†ØªÙŠØ¬Ø© Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØµÙ†ÙŠÙ:")
                    st.write(f"- Ø§Ù„ØªÙ†Ø¨Ø¤: **{pred}**")
                    # Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¶Ø§ÙØ© Ø®Ø±ÙŠØ·Ø© ØªÙØ³ÙŠØ±ÙŠØ© Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                    st.write("ØªÙØ³ÙŠØ± Ù…Ø¨Ø³Ø·: Ù‡Ø°Ø§ ØªÙˆÙ‚Ø¹ Ø¢Ù„ÙŠ ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ Decision Tree. Ù„Ø§ ÙŠØºÙ†ÙŠ Ø¹Ù† ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø·Ø¨ÙŠØ¨.")
            st.info("âš ï¸ Ù‡Ø°Ø§ ØªØ­Ù„ÙŠÙ„ Ø£ÙˆÙ„ÙŠ ÙˆÙ„Ø§ ÙŠØºÙ†ÙŠ Ø¹Ù† Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø·Ø¨ÙŠØ¨.")

# Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
st.sidebar.markdown("---")
st.sidebar.write("ØªÙ… Ø§Ù„ØªØ·ÙˆÙŠØ± Ø¨ÙˆØ§Ø³Ø·Ø© ÙØ±ÙŠÙ‚Ùƒ â€” ÙŠÙ…ÙƒÙ†Ùƒ ØªØ²ÙˆÙŠØ¯ÙŠ Ø¨Ù€Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ `.joblib` Ù„Ø£Ø¯Ù…Ø¬Ù‡ Ø¥Ù† Ø±ØºØ¨Øª.")
