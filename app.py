import streamlit as st
import re
import io
import numpy as np
import pandas as pd
from openai import OpenAI
import cv2
import easyocr
# import pytesseract # <-- ØªÙ… Ø­Ø°ÙÙ‡
import joblib
from PIL import Image
import os
from tensorflow.keras.models import load_model
import altair as alt

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(
    page_title="AI Medical Suite",
    page_icon="âš•ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ (EasyOCR ÙÙ‚Ø·) ---
@st.cache_resource
def load_ocr_model():
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ÙÙ‚Ø· Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¯Ù‚Ø©
    return easyocr.Reader(['en'])

# ... (Ø¨Ø§Ù‚ÙŠ Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙˆÙ‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ ØªÙ…Ø§Ù…Ù‹Ø§) ...
@st.cache_data
def load_symptom_checker():
    try:
        s_model = joblib.load('symptom_checker_model.joblib')
        s_data = pd.read_csv('Training.csv')
        s_list = s_data.columns[:-1].tolist()
        return s_model, s_list
    except FileNotFoundError:
        return None, None

@st.cache_resource
def load_ecg_analyzer():
    try:
        ecg_model = load_model("ecg_classifier_model.h5")
        ecg_signals = np.load("sample_ecg_signals.npy", allow_pickle=True).item()
        return ecg_model, ecg_signals
    except FileNotFoundError:
        return None, None

KNOWLEDGE_BASE = {
    "wbc": {"name_ar": "ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡", "aliases": ["w.b.c", "white blood cells"], "range": (4.0, 11.0), "unit": "x10^9/L", "category": "Ø§Ù„Ø§Ù„ØªÙ‡Ø§Ø¨Ø§Øª ÙˆØ§Ù„Ù…Ù†Ø§Ø¹Ø©", "recommendation_high": "Ø§Ø±ØªÙØ§Ø¹ Ù‚Ø¯ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø¹Ø¯ÙˆÙ‰ Ø¨ÙƒØªÙŠØ±ÙŠØ©.", "recommendation_low": "Ø§Ù†Ø®ÙØ§Ø¶ Ù‚Ø¯ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø¶Ø¹Ù Ù…Ù†Ø§Ø¹ÙŠ."},
    "rbc": {"name_ar": "ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø­Ù…Ø±Ø§Ø¡", "aliases": ["r.b.c", "red blood cells"], "range": (4.1, 5.9), "unit": "x10^12/L", "category": "ÙØ­ÙˆØµØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø¹Ø§Ù…Ø©", "recommendation_high": "Ø§Ø±ØªÙØ§Ø¹ Ù‚Ø¯ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ø¬ÙØ§Ù.", "recommendation_low": "Ø§Ù†Ø®ÙØ§Ø¶ Ù‚Ø¯ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ ÙÙ‚Ø± Ø¯Ù…."},
    "hemoglobin": {"name_ar": "Ø§Ù„Ù‡ÙŠÙ…ÙˆØºÙ„ÙˆØ¨ÙŠÙ†", "aliases": ["hb", "hgb"], "range": (13.0, 18.0), "unit": "g/dL", "category": "ÙØ­ÙˆØµØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø¹Ø§Ù…Ø©", "recommendation_high": "Ø§Ø±ØªÙØ§Ø¹ Ù‚Ø¯ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ø¬ÙØ§Ù.", "recommendation_low": "Ø§Ù†Ø®ÙØ§Ø¶ Ù‡Ùˆ Ù…Ø¤Ø´Ø± Ø£Ø³Ø§Ø³ÙŠ Ø¹Ù„Ù‰ ÙÙ‚Ø± Ø§Ù„Ø¯Ù…."},
    "platelets": {"name_ar": "Ø§Ù„ØµÙØ§Ø¦Ø­ Ø§Ù„Ø¯Ù…ÙˆÙŠØ©", "aliases": ["plt"], "range": (150, 450), "unit": "x10^9/L", "category": "ÙØ­ÙˆØµØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø¹Ø§Ù…Ø©", "recommendation_high": "Ø§Ø±ØªÙØ§Ø¹ Ù‚Ø¯ ÙŠØ²ÙŠØ¯ Ù…Ù† Ø®Ø·Ø± Ø§Ù„Ø¬Ù„Ø·Ø§Øª.", "recommendation_low": "Ø§Ù†Ø®ÙØ§Ø¶ Ù‚Ø¯ ÙŠØ²ÙŠØ¯ Ù…Ù† Ø®Ø·Ø± Ø§Ù„Ù†Ø²ÙŠÙ."},
    "color": {"name_ar": "Ù„ÙˆÙ† Ø§Ù„Ø¨ÙˆÙ„", "aliases": ["colour"], "range": (0, 0), "unit": "", "category": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙˆÙ„", "recommendation_high": "Ù„ÙˆÙ† Ø¯Ø§ÙƒÙ† Ù‚Ø¯ ÙŠØ´ÙŠØ± Ù„Ø¬ÙØ§ÙØŒ Ù„ÙˆÙ† Ø£Ø­Ù…Ø± Ù‚Ø¯ ÙŠØ´ÙŠØ± Ù„ÙˆØ¬ÙˆØ¯ Ø¯Ù….", "recommendation_low": ""},
    "appearance": {"name_ar": "Ø¹ÙƒØ§Ø±Ø© Ø§Ù„Ø¨ÙˆÙ„", "aliases": ["clarity"], "range": (0, 0), "unit": "", "category": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙˆÙ„", "recommendation_high": "Ø¹ÙƒØ§Ø±Ø© Ù‚Ø¯ ØªØ´ÙŠØ± Ù„ÙˆØ¬ÙˆØ¯ Ø§Ù„ØªÙ‡Ø§Ø¨ Ø£Ùˆ Ø£Ù…Ù„Ø§Ø­.", "recommendation_low": ""},
    "ph": {"name_ar": "Ø­Ù…ÙˆØ¶Ø© Ø§Ù„Ø¨ÙˆÙ„ (pH)", "aliases": ["p.h", "p h"], "range": (4.5, 8.0), "unit": "", "category": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙˆÙ„", "recommendation_high": "Ù‚Ù„ÙˆÙŠØ© Ø§Ù„Ø¨ÙˆÙ„ Ù‚Ø¯ ØªØ´ÙŠØ± Ù„Ø§Ù„ØªÙ‡Ø§Ø¨.", "recommendation_low": "Ø­Ù…Ø¶ÙŠØ© Ø§Ù„Ø¨ÙˆÙ„ Ù‚Ø¯ ØªØ±ØªØ¨Ø· Ø¨Ø­ØµÙˆØ§Øª Ù…Ø¹ÙŠÙ†Ø©."},
    "sg": {"name_ar": "Ø§Ù„ÙƒØ«Ø§ÙØ© Ø§Ù„Ù†ÙˆØ¹ÙŠØ© (SG)", "aliases": ["specific gravity", "gravity"], "range": (1.005, 1.030), "unit": "", "category": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙˆÙ„", "recommendation_high": "Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„ÙƒØ«Ø§ÙØ© Ù‚Ø¯ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ø¬ÙØ§Ù.", "recommendation_low": "Ø§Ù†Ø®ÙØ§Ø¶ Ø§Ù„ÙƒØ«Ø§ÙØ© Ù‚Ø¯ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø´Ø±Ø¨ ÙƒÙ…ÙŠØ§Øª ÙƒØ¨ÙŠØ±Ø© Ù…Ù† Ø§Ù„Ù…Ø§Ø¡."},
    "leukocytes": {"name_ar": "ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡", "aliases": ["leukocyte", "leu"], "range": (0, 0), "unit": "", "category": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙˆÙ„", "recommendation_high": "ÙˆØ¬ÙˆØ¯Ù‡Ø§ Ù‡Ùˆ Ø¹Ù„Ø§Ù…Ø© Ù‚ÙˆÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„ØªÙ‡Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§Ù„Ùƒ Ø§Ù„Ø¨ÙˆÙ„ÙŠØ©.", "recommendation_low": ""},
    "pus": {"name_ar": "Ø®Ù„Ø§ÙŠØ§ Ø§Ù„ØµØ¯ÙŠØ¯", "aliases": ["pus cells"], "range": (0, 5), "unit": "/HPF", "category": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙˆÙ„", "recommendation_high": "Ø§Ø±ØªÙØ§Ø¹ Ø¹Ø¯Ø¯Ù‡Ø§ ÙŠØ¤ÙƒØ¯ ÙˆØ¬ÙˆØ¯ Ø§Ù„ØªÙ‡Ø§Ø¨ Ø¨ÙˆÙ„ÙŠ.", "recommendation_low": ""},
    "rbcs": {"name_ar": "ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø­Ù…Ø±Ø§Ø¡", "aliases": ["rbc's", "red blood cells", "blood"], "range": (0, 2), "unit": "/HPF", "category": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙˆÙ„", "recommendation_high": "ÙˆØ¬ÙˆØ¯ Ø¯Ù… ÙÙŠ Ø§Ù„Ø¨ÙˆÙ„ ÙŠØªØ·Ù„Ø¨ Ø§Ø³ØªØ´Ø§Ø±Ø© Ø·Ø¨ÙŠØ© Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø³Ø¨Ø¨.", "recommendation_low": ""},
}
def analyze_text_robust(text):
    if not text: return []
    results = []
    text_lower = text.lower()
    found_numbers = [(m.group(1), m.start()) for m in re.finditer(r'(\d+\.?\d*)', text_lower)]
    found_tests = []
    for key, details in KNOWLEDGE_BASE.items():
        search_terms = [key] + details.get("aliases", [])
        for term in search_terms:
            pattern = re.compile(rf'\b{re.escape(term)}\b', re.IGNORECASE)
            for match in pattern.finditer(text_lower):
                found_tests.append({'key': key, 'pos': match.end()})
                break
            else:
                continue
            break
    found_tests.sort(key=lambda x: x['pos'])
    unique_found_keys = []
    for test in found_tests:
        if test['key'] not in [t['key'] for t in unique_found_keys]:
             unique_found_keys.append(test)
    for test in unique_found_keys:
        key = test['key']
        best_candidate_val = None
        min_distance = float('inf')
        for num_val, num_pos in found_numbers:
            distance = num_pos - test['pos']
            if 0 < distance < 50:
                if num_pos + len(num_val) < len(text_lower) and text_lower[num_pos + len(num_val)].isalpha():
                    continue
                min_distance = distance
                best_candidate_val = num_val
                break
        if best_candidate_val:
            try:
                value = float(best_candidate_val)
                details = KNOWLEDGE_BASE[key]
                low, high = details["range"]
                status = "Ø·Ø¨ÙŠØ¹ÙŠ"
                if value < low: status = "Ù…Ù†Ø®ÙØ¶"
                elif value > high: status = "Ù…Ø±ØªÙØ¹"
                results.append({
                    "name": details['name_ar'], "value": value, "status": status,
                    "recommendation": details.get(f"recommendation_{status.lower()}", details.get("recommendation_high", "") if status == "Ù…Ø±ØªÙØ¹" else ""),
                    "category": details.get("category", "Ø¹Ø§Ù…")
                })
            except (ValueError, KeyError):
                continue
    return results
def display_results(results):
    if not results:
        st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø£ÙŠ ÙØ­ÙˆØµØ§Øª Ù…Ø¯Ø¹ÙˆÙ…Ø© ÙÙŠ Ø§Ù„ØªÙ‚Ø±ÙŠØ±.")
        return
    grouped = {}
    for res in results:
        cat = res.get("category", "Ø¹Ø§Ù…")
        if cat not in grouped: grouped[cat] = []
        grouped[cat].append(res)
    sorted_categories = sorted(grouped.keys())
    for category in sorted_categories:
        st.subheader(f"ğŸ“ {category}")
        for r in results:
            if r['category'] == category:
                status_color = "green" if r['status'] == 'Ø·Ø¨ÙŠØ¹ÙŠ' else "orange" if r['status'] == 'Ù…Ù†Ø®ÙØ¶' else "red"
                st.markdown(f"**{r['name']}**: {r['value']}  <span style='color:{status_color}; font-weight:bold;'>({r['status']})</span>", unsafe_allow_html=True)
                if r['recommendation']:
                    st.info(f"ğŸ’¡ {r['recommendation']}")
        st.markdown("---")
def plot_signal(signal, title):
    df = pd.DataFrame({'Time': range(len(signal)), 'Amplitude': signal})
    chart = alt.Chart(df).mark_line(color='#FF4B4B').encode(x=alt.X('Time', title='Ø§Ù„Ø²Ù…Ù†'), y=alt.Y('Amplitude', title='Ø§Ù„Ø³Ø¹Ø©'), tooltip=['Time', 'Amplitude']).properties(title=title).interactive()
    st.altair_chart(chart, use_container_width=True)

# --- Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (ØªÙ… ØªØ¨Ø³ÙŠØ·Ù‡Ø§ Ù„Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ EasyOCR ÙÙ‚Ø·) ---
st.title("âš•ï¸ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø·Ø¨ÙŠØ© Ø§Ù„Ø°ÙƒÙŠØ©")
st.sidebar.header("Ø§Ø®ØªØ± Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©")
mode = st.sidebar.radio("Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:", ("ğŸ”¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ© (OCR)", "ğŸ©º Ù…Ø¯Ù‚Ù‚ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ø°ÙƒÙŠ", "ğŸ’“ Ù…Ø­Ù„Ù„ Ø¥Ø´Ø§Ø±Ø§Øª ECG"))
st.sidebar.markdown("---")
api_key_input = st.sidebar.text_input("ğŸ”‘ Ø£Ø¯Ø®Ù„ Ù…ÙØªØ§Ø­ OpenAI API (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", type="password")

if mode == "ğŸ”¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ© (OCR)":
    st.header("ğŸ”¬ ØªØ­Ù„ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ø·Ø¨ÙŠ (ØµÙˆØ±Ø©)")
    uploaded_file = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØ±Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù‡Ù†Ø§", type=["png","jpg","jpeg"])
    
    if uploaded_file:
        file_bytes = uploaded_file.getvalue()
        text = None
        
        # --- Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©: Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø§Ù„ÙƒØ§Ù…Ù„ Ø¹Ù„Ù‰ EasyOCR Ù„Ù„Ù…ÙˆØ«ÙˆÙ‚ÙŠØ© ---
        with st.spinner("Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… (EasyOCR) ÙŠØ­Ù„Ù„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¢Ù†... (Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ø¨Ø¹Ø¶ Ø§Ù„ÙˆÙ‚Øª)"):
            try:
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
                img = Image.open(io.BytesIO(file_bytes)).convert('L')
                img.thumbnail((1200, 1200), Image.Resampling.LANCZOS)
                buffered = io.BytesIO()
                img.save(buffered, format="PNG")
                img_bytes_processed = buffered.getvalue()
                
                reader = load_ocr_model()
                raw_results = reader.readtext(img_bytes_processed, detail=0, paragraph=True)
                text = "\n".join(raw_results)
                st.success("ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø¬Ø§Ø­!")
            except Exception as e:
                st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙØ§Ø¯Ø­ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {e}")
                text = None

        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        if text:
            with st.expander("ğŸ“„ Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬"):
                st.text_area("Ø§Ù„Ù†Øµ:", text, height=250)
            
            final_results = analyze_text_robust(text)
            display_results(final_results)
        elif text is None:
            # Ù„Ø§ ØªÙØ¹Ù„ Ø´ÙŠØ¦Ù‹Ø§ØŒ ÙÙ‚Ø¯ ØªÙ… Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£ Ø¨Ø§Ù„ÙØ¹Ù„
            pass
        else:
            st.error("Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ø§Ù„Ù…Ø­Ø±Ùƒ Ù…Ù† Ù‚Ø±Ø§Ø¡Ø© Ø£ÙŠ Ù†Øµ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©.")

elif mode == "ğŸ©º Ù…Ø¯Ù‚Ù‚ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø§Ù„Ø°ÙƒÙŠ":
    # ... (Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù‡Ø°Ø§ Ø§Ù„ÙˆØ¶Ø¹ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©) ...
    pass
elif mode == "ğŸ’“ Ù…Ø­Ù„Ù„ Ø¥Ø´Ø§Ø±Ø§Øª ECG":
    # ... (Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù‡Ø°Ø§ Ø§Ù„ÙˆØ¶Ø¹ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©) ...
    pass
