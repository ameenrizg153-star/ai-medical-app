import streamlit as st
import re
import io
from PIL import Image
import pytesseract
import pdfplumber
import pandas as pd
import cv2
import numpy as np
from pdf2image import convert_from_bytes
import joblib

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(
    page_title="AI Medical Analyzer",
    page_icon="ğŸ©º",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ­ÙˆØµØ§Øª ---
NORMAL_RANGES = {
    "wbc": {"range": (4000, 11000), "unit": "cells/mcL", "name_ar": "ÙƒØ±ÙŠØ§Øª Ø§Ù„Ø¯Ù… Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡"},
    "hemoglobin": {"range": (12.0, 17.5), "unit": "g/dL", "name_ar": "Ø§Ù„Ù‡ÙŠÙ…ÙˆØºÙ„ÙˆØ¨ÙŠÙ†"},
    "glucose": {"range": (70, 140), "unit": "mg/dL", "name_ar": "Ø§Ù„Ø¬Ù„ÙˆÙƒÙˆØ² (Ø§Ù„Ø³ÙƒØ±)"},
    "creatinine": {"range": (0.6, 1.3), "unit": "mg/dL", "name_ar": "Ø§Ù„ÙƒØ±ÙŠØ§ØªÙŠÙ†ÙŠÙ†"},
    "vitamin_d": {"range": (30, 100), "unit": "ng/mL", "name_ar": "ÙÙŠØªØ§Ù…ÙŠÙ† D"},
    "crp": {"range": (0, 5), "unit": "mg/L", "name_ar": "Ø¨Ø±ÙˆØªÙŠÙ† Ø³ÙŠ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ (CRP)"},
}

ALIASES = {
    "blood sugar": "glucose",
    "hb": "hemoglobin",
    "sugar": "glucose"
}

# --- ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ ---
@st.cache_resource
def load_model():
    try:
        model = joblib.load("symptom_checker_model.joblib")
        return model
    except:
        return None

model = load_model()

# --- Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ù‚Ø¨Ù„ OCR ---
def preprocess_image(img):
    gray = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2GRAY)
    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)
    return Image.fromarray(thresh)

# --- Ù‚Ø±Ø§Ø¡Ø© ØµÙˆØ±Ø© ---
def extract_text_from_image(file_bytes):
    try:
        img = Image.open(io.BytesIO(file_bytes))
        img = preprocess_image(img)
        text = pytesseract.image_to_string(img, lang="eng+ara")
        return text, None
    except Exception as e:
        return None, f"OCR Error: {e}"

# --- Ù‚Ø±Ø§Ø¡Ø© PDF (Ù†Øµ + ØµÙˆØ±) ---
def extract_text_from_pdf(file_bytes):
    texts = []
    errors = []
    try:
        with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    texts.append(page_text)

        if not texts:
            pages = convert_from_bytes(file_bytes)
            for i, page_img in enumerate(pages):
                try:
                    page_img = preprocess_image(page_img)
                    txt = pytesseract.image_to_string(page_img, lang="eng+ara")
                    texts.append(txt)
                except Exception as e:
                    errors.append(f"Error OCR page {i+1}: {e}")
    except Exception as e:
        return None, f"PDF Error: {e}"

    return "\n".join(texts), (errors if errors else None)

# --- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·Ø¨ÙŠØ© ---
def analyze_text(text):
    results = []
    if not text:
        return results
    text_lower = text.lower()
    for key, details in NORMAL_RANGES.items():
        aliases = [k for k, v in ALIASES.items() if v == key]
        search_keys = [key] + aliases
        pattern = re.compile(rf"\b({'|'.join(search_keys)})\b[:\-= ]*([0-9]+(?:\.[0-9]+)?)", re.IGNORECASE)
        matches = pattern.finditer(text_lower)
        for m in matches:
            try:
                value = float(m.group(2))
                low, high = details["range"]
                status = "Normal"
                if value < low:
                    status = "Low"
                elif value > high:
                    status = "High"
                results.append({
                    "Ø§Ù„ÙØ­Øµ": details["name_ar"],
                    "Ø§Ù„Ù‚ÙŠÙ…Ø©": value,
                    "Ø§Ù„ÙˆØ­Ø¯Ø©": details["unit"],
                    "Ø§Ù„Ø­Ø§Ù„Ø©": status,
                    "Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ": f"{low}-{high}"
                })
            except:
                continue
    return results

# --- ÙˆØ§Ø¬Ù‡Ø© ---
st.sidebar.header("ğŸ“Œ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©")
mode = st.sidebar.radio("Ø§Ø®ØªØ± Ø§Ù„Ø®Ø¯Ù…Ø©:", ["ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ©", "Ø§Ø³ØªØ´Ø§Ø±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶"])

if mode == "ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø·Ø¨ÙŠØ©":
    st.header("ğŸ”¬ ØªØ­Ù„ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ø·Ø¨ÙŠ (PDF Ø£Ùˆ ØµÙˆØ±Ø©)")
    uploaded_file = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„Ù", type=["png","jpg","jpeg","pdf"])
    if uploaded_file:
        file_bytes = uploaded_file.getvalue()
        text, err = (extract_text_from_pdf(file_bytes) if "pdf" in uploaded_file.type
                     else extract_text_from_image(file_bytes))
        if err: st.error(err)
        if text:
            st.subheader("ğŸ“„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬:")
            st.text_area("Extracted Text", text, height=200)
            results = analyze_text(text)
            if results:
                df = pd.DataFrame(results)
                st.subheader("ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„:")
                st.dataframe(df, use_container_width=True)
                abnormal = df[df["Ø§Ù„Ø­Ø§Ù„Ø©"] != "Normal"]
                if not abnormal.empty:
                    st.error("âš ï¸ ÙŠÙˆØ¬Ø¯ ÙØ­ÙˆØµØ§Øª ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠØ© ØªØ­ØªØ§Ø¬ Ù…ØªØ§Ø¨Ø¹Ø© Ø·Ø¨ÙŠØ©.")
            else:
                st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø£ÙŠ ÙØ­ÙˆØµØ§Øª.")
elif mode == "Ø§Ø³ØªØ´Ø§Ø±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶":
    st.header("ğŸ’¬ Ø§Ø³ØªØ´Ø§Ø±Ø© Ø£ÙˆÙ„ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶")
    symptoms = st.text_area("ğŸ“ ØµÙ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶:", height=150)
    if st.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶"):
        if symptoms:
            if model:
                st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡.")
                st.info("âš ï¸ Ù…Ø¨Ø¯Ø¦ÙŠÙ‹Ø§ØŒ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØªÙ†Ø¨Ø£ Ø¨Ø§Ù„Ø­Ø§Ù„Ø© Ø­Ø³Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¯Ø®Ù„Ø©.")
            else:
                st.warning("ğŸš¨ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ (symptom_checker_model.joblib).")
        else:
            st.warning("ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶.")
